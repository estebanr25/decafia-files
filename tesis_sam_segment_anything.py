# -*- coding: utf-8 -*-
"""TESIS_SAM_segment_anything.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/128oBM5l8fQbyK8xQjjWPVj-mb0pgz3nL

# Model Segment Anything (SAM), UNA OPCION INTERESANTE PARA ETIQUETADO DE MASCARAS UTILIZADOS EN ENTRENAMIENTOS BASADOS EN SEGMENTACI칍N SEMANTICA.

---

Modelo Segment Anything (SAM): un nuevo modelo de IA de Meta AI que puede "recortar" cualquier objeto, en cualquier imagen, con un solo clic. SAM es un sistema de segmentaci칩n que se puede solicitar con generalizaci칩n de cero disparos a objetos e im치genes desconocidos, sin necesidad de entrenamiento adicional. Este cuaderno es una extensi칩n del [cuaderno oficial](https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb) preparado por Meta AI.

El Modelo Segment Anything (SAM) representa una opci칩n altamente prometedora en el 치mbito del etiquetado de m치scaras utilizado en entrenamientos basados en segmentaci칩n sem치ntica. SAM ofrece una soluci칩n avanzada y vers치til para la tarea crucial de segmentaci칩n de im치genes, permitiendo a los investigadores y practicantes del aprendizaje autom치tico abordar una amplia gama de aplicaciones de manera efectiva. Esta introducci칩n explorar치 c칩mo SAM se destaca como una herramienta integral y eficiente para la generaci칩n de m치scaras precisas y detalladas, allanando el camino para avances significativos en la comprensi칩n y manipulaci칩n de datos visuales.

![modelo segment anything](https://media.roboflow.com/notebooks/examples/segment-anything-model-paper.png)
## SAM como una herramienta semi-asistida
 se podr칤a considerar a SAM como una herramienta semi-asistida para el etiquetado de im치genes en el contexto de tareas de segmentaci칩n. Aunque SAM no es un etiquetador en s칤 mismo, sino un modelo de segmentaci칩n, puede facilitar significativamente el proceso de etiquetado proporcionando predicciones precisas de m치scaras para las im치genes. Esto puede ayudar a los usuarios a realizar el etiquetado de manera m치s eficiente al reducir la carga manual de generar m치scaras para segmentar objetos en las im치genes. Sin embargo, a칰n requiere la interacci칩n humana para proporcionar las cajas delimitadoras o indicaciones necesarias para generar las m치scaras.

## Consejo profesional: Utiliza la Aceleraci칩n de GPU

Si est치s ejecutando este cuaderno en Google Colab, ve a `Editar` -> `Configuraci칩n del cuaderno` -> `Acelerador de hardware`, config칰ralo en `GPU` y luego haz clic en `Guardar`. Esto asegurar치 que tu cuaderno utilice una GPU, lo que acelerar치 significativamente los tiempos de entrenamiento del modelo.

## Pasos en este Tutorial

En este tutorial, vamos a cubrir:

- **Antes de empezar** - Aseg칰rate de tener acceso a la GPU
- Instalar el Modelo Segment Anything (SAM)
- Cargar el Modelo
- Generaci칩n Autom치tica de M치scaras
- Generar Segmentaci칩n con Cuadro delimitador
- Segmentar Cualquier Cosa en el Conjunto de Datos del Universo Roboflow

## 춰Comencemos!

## Antes de empezar

Asegur칠monos de tener acceso a la GPU. Podemos usar el comando `nvidia-smi` para hacerlo. En caso de cualquier problema, navega a `Editar` -> `Configuraci칩n del cuaderno` -> `Acelerador de hardware`, config칰ralo en `GPU` y luego haz clic en `Guardar`.
"""

!nvidia-smi

"""Este c칩digo cambia al directorio actual, instala el modelo SAM y sus dependencias utilizando pip, y muestra el directorio actual antes de realizar la instalaci칩n.

NOTA: Para facilitarnos la gesti칩n de conjuntos de datos, im치genes y modelos que creamos, creamos una constante llamada `HOME`.
"""

# Commented out IPython magic to ensure Python compatibility.
import os
# El directorio de trabajo actual es el directorio desde el cual se est치 ejecutando el script o el programa en ese momento.
HOME = os.getcwd()
print("HOME:", HOME)
#Install Segment Anything Model (SAM) and other dependencies
# %cd {HOME}
import sys
!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'

"""Se instala los paquetes que roporcionan herramientas y utilidades 칰tiles para el desarrollo de proyectos de visi칩n por computadora y aprendizaje autom치tico en entornos de `Jupyter Notebooks`. `jupyter_bbox_widget` ofrece un widget interactivo para trabajar con cuadros delimitadores en im치genes dentro de los notebooks. `roboflow` facilita tareas de preprocesamiento, aumento y conversi칩n de conjuntos de datos de visi칩n por computadora. `dataclasses-json` simplifica la serializaci칩n y deserializaci칩n de objetos de datos definidos por el usuario a/desde JSON. Por 칰ltimo, `supervision*` proporciona herramientas para la gesti칩n y supervisi칩n de tareas de aprendizaje autom치tico, como entrenamiento y evaluaci칩n de modelos, as칤 como gesti칩n de conjuntos de datos."""

!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision

"""### DESCARGAR PESOS"""

# Commented out IPython magic to ensure Python compatibility.
# Cambiar al directorio HOME
# %cd {HOME}
# Crear un directorio llamado "weights" dentro del directorio HOME
!mkdir {HOME}/weights
# Cambiar al directorio "weights" reci칠n creado
# %cd {HOME}/weights
# El modelo se descarga desde una URL espec칤fica y se almacena en el directorio "weights"
!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth
# Importar el m칩dulo os para trabajar con rutas de archivo y directorio
import os
# Crear la ruta completa al archivo de punto de control (checkpoint) descargado
CHECKPOINT_PATH = os.path.join(HOME, "weights", "sam_vit_h_4b8939.pth")
# Imprimir la ruta completa del archivo de punto de control y verificar si existe
print(CHECKPOINT_PATH, "; exist:", os.path.isfile(CHECKPOINT_PATH))

"""## CARGAR MODELO"""

# Importar la biblioteca PyTorch
import torch
# Determinar el dispositivo de c칩mputo (GPU o CPU) disponible
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
# Definir el tipo de modelo a utilizar
MODEL_TYPE = "vit_h"
# Importar las clases y funciones necesarias de la biblioteca "segment_anything"
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
# Crear una instancia del modelo SAM correspondiente al tipo de modelo especificado
# Se carga el modelo previamente descargado (CHECKPOINT_PATH) y se mueve al dispositivo disponible (DEVICE)
sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)

"""# **CARGAR FUNCIONES PARA GRAFICAR MASCARAS, CAJAS Y SELECCION DE IMAGENES A ETIQUETAR**"""

import matplotlib.pyplot as plt
import json
import numpy as np
import os
from scipy.spatial import ConvexHull
import cv2
import matplotlib.patches as patches
import supervision as sv
from datetime import datetime
import pytz


def plot_binary_masks(mask_set):
    """" Esta funci칩n toma un conjunto de m치scaras binarias como entrada y las visualiza en una cuadr칤cula de subgr치ficos.
         Cada m치scara se muestra en su propio subplot con un t칤tulo correspondiente, y los ejes se ocultan para una presentaci칩n
         m치s limpia.
    """
    # Obtener el n칰mero de m치scaras en el conjunto
    num_masks = len(mask_set)
    # Definir el n칰mero de columnas para organizar las m치scaras en la visualizaci칩n
    cols = 3  # Puedes ajustar el n칰mero de columnas seg칰n tu preferencia
    # Calcular el n칰mero de filas necesario para acomodar todas las m치scaras
    rows = (num_masks + cols - 1) // cols
    # Configurar el tama침o de la figura
    plt.figure(figsize=(15, 5 * rows))
    # Iterar sobre cada m치scara en el conjunto
    for i, mask in enumerate(mask_set, 1):
        # Crear un subplot correspondiente a cada m치scara
        plt.subplot(rows, cols, i)
        # Mostrar la m치scara en el subplot actual
        plt.imshow(mask, cmap='binary')
        # Configurar el t칤tulo del subplot
        plt.title(f'Mask OPCION {i}')
        # Ocultar los ejes en el subplot
        plt.axis('off')
    plt.show()

# funcion que imprime la mascara de la hoja individual.
def plot_binary_mask2(mask, title='Mask'):
    plt.figure(figsize=(11, 11))
    plt.imshow(mask, cmap='binary')
    plt.title(title)
    plt.axis('off')
    plt.show()


def dibujar_cajas(image_path, cajas):
    """" muestra una imagen (seleccion de la etiqueta del objeto a segmentar) con las cajas delimitadoras superpuestas en ella
         lo que es util para mostrar las cajas seleccionadas
    """
    # Leer la imagen
    image_bgr = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    # Crear una figura y un conjunto de ejes
    #plt.figure(figsize=(10, 10))
    fig, ax = plt.subplots(figsize=(10, 10))
    # Mostrar la imagen
    ax.imshow(image_rgb)
    # Iterar sobre las cajas y dibujarlas en la imagen
    for box in cajas:
        x, y, w, h = box['x'], box['y'], box['width'], box['height']
        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
    # Mostrar la imagen con las cajas
    plt.show()



def procesar_imagen(IMAGE_PATH, widget, mask_predictor,  OP):
    """"
        Esta funci칩n procesar_imagen toma como entrada la ruta de la imagen (IMAGE_PATH),
        un widget que contiene las cajas delimitadoras seleccionadas (widget),
        un objeto que representa el modelo de predicci칩n de m치scaras (mask_predictor),
        y una opci칩n OP que determina si se debe incluir o no la 칰ltima m치scara en el resultado final.

        Esta funci칩n procesa una imagen segmentando las 치reas de inter칠s definidas por las cajas delimitadoras
        y acumula las m치scaras resultantes. La opci칩n OP permite controlar si se incluye o no la 칰ltima m치scara
        en el resultado final.
    """
    boxx = []

    # Recorrer las cajas y construir un array con las coordenadas
    for i in range(len(widget.bboxes)):
        box = widget.bboxes[i]
        boxx.append(np.array([
            box['x'],
            box['y'],
            box['x'] + box['width'],
            box['y'] + box['height']
        ]))

    # Leer la imagen
    image_bgr = cv2.imread(IMAGE_PATH)
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    #  prepara el modelo para procesar la imagen image_rgb.
    mask_predictor.set_image(image_rgb)
    # crea una matriz de ceros con el mismo tama침o de la imagen RGB, cada elemento de la matriz representa un entero sin signo de 8 bits.
    # Esta matriz se utilizar치 posteriormente para acumular las m치scaras de segmentaci칩n resultantes.
    cumulative_mask = np.zeros_like(image_rgb[:, :, 0], dtype=np.uint8)

    scoress = []
    logitss = []
    maskss = []
    # este bucle procesa todas las cajas delimitadoras, predice las m치scaras correspondientes
    # y acumula las m치scaras predichas seg칰n el valor de OP.
    for i in range(len(boxx)):
        masks, scores, logits = mask_predictor.predict(
            box=boxx[i],
            multimask_output=True
        )

        if i < len(boxx) - OP:
            cumulative_mask = cumulative_mask | masks

        scoress.append(scores)
        logitss.append(logits)
        maskss.append(masks)

    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)

    return scoress, logitss, maskss, cumulative_mask, boxx

def ACTUALIZAR_MASK(boxx, mask_predictor,  OP=1, OPCION=2,OPCION2=2):
    """" Esta funci칩n toma una lista de cajas delimitadoras (boxx), un predictor de m치scaras (mask_predictor),
         y varios par치metros (OP, OPCION, OPCION2) para actualizar las m치scaras asociadas con las regiones de inter칠s
         definidas por las cajas delimitadoras. La funci칩n devuelve una lista de m치scaras actualizadas
         y proporciona informaci칩n sobre el n칰mero de m치scaras
    """
    lista_de_mascaras = []
    # Iterar sobre cada caja delimitadora en la lista boxx
    for i in range(len(boxx)):
        # Predecir la m치scara correspondiente a la regi칩n de inter칠s definida por la caja delimitadora
        masks, scores, logits = mask_predictor.predict(
            box=boxx[i],
            multimask_output=True
        )
        # Dependiendo de la opcion incluye o excluye la ultima etiqueta con el fin de tener una mejor visulizacion
        # de las etiquetas
        if i < len(boxx)-OP:
            lista_de_mascaras.append(masks[OPCION-1])
        elif i == len(boxx)-OP:
            lista_de_mascaras.append(masks[OPCION2-1])

    print(f"{'Numero de Box:'}{len(lista_de_mascaras)}")
    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)
    return lista_de_mascaras

from shapely.geometry import Polygon

def crear_polygon_desde_vectores( x, y):
    """" Esta funci칩n proporciona una forma conveniente de crear un objeto de pol칤gono
        a partir de las coordenadas de los v칠rtices del pol칤gono.
    """
    # Combinar las coordenadas x e y en un array bidimensional
    coordenadas = np.column_stack((x, y))
    # Crear un objeto de pol칤gono utilizando las coordenadas
    return Polygon(coordenadas)

################################################################################
# ESTRUCTURA DEL FORMATO .JSON ADAPTADO PARA UTILIZAR LA HERRAMIENTA DE (VGG)
# https://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.0.html

       # Load annotations
        # VGG Image Annotator saves each image in the form:
        # { 'filename': 'IMAGEN.jpg',
        #   'regions': {
        #       '0': {
        #           'region_attributes': {},
        #           'shape_attributes': {
        #               'all_points_x': [...],
        #               'all_points_y': [...],
        #               'name': 'polygon'}},
        #       ... more regions ...
        #   },
        #   'size': 80202
        # }
        # We mostly care about the x and y coordinates of each region
################################################################################

def convertir_JSON(boxx, IMAGE_PATH, widget, lista_de_mascaras, CLASE, OP,ver):
    # Crear el nombre del archivo
    points_x=[]
    points_y=[]
    # define el nombre de archivo  en formato .json apartir del nombre de la imagen
    nombre_archivo = f"{os.path.basename(IMAGE_PATH)}{os.path.getsize(IMAGE_PATH)}"
    caja_con_mascara = {
        "fileref": "",
        "size": os.path.getsize(IMAGE_PATH),  # Ajusta el tama침o seg칰n tus necesidades
        "filename": nombre_archivo,  # Ajusta el formato del nombre del archivo
        "base64_img_data": "",
        "file_attributes": {},
        "regions": {}
    }
    # Cajas y las m치scaras en listas separadas
    lista_de_cajas = widget.bboxes
    # Crear la estructura deseada
    estructura_deseada = {}
    # Agregar las regiones al diccionario
    for i, mascara in enumerate(lista_de_mascaras):
        binary_image=lista_de_mascaras[i]
        # Convertir la imagen binaria a una imagen con valores 0 y 255 (negro y blanco)
        binary_image_as_uint8 = binary_image.astype(np.uint8) * 255

        # Crear una imagen en blanco
        height, width = binary_image.shape
        image = np.zeros((height, width, 3), dtype=np.uint8)

        # Obtener las coordenadas (칤ndices) donde los valores son True
        indices_true = np.where(binary_image)

        # Crear una lista de puntos (x, y) a partir de las coordenadas
        points = np.column_stack((indices_true[1], indices_true[0]))

        # Dibujar el pol칤gono en la imagen en blanco
        cv2.fillPoly(image, [points], color=(255, 255, 255))

        # Encontrar los contornos en la imagen binaria original
        # cv2.findContours() devuelve una lista de contornos
        contours, _ = cv2.findContours(binary_image_as_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Encontrar el contorno principal dentro de la lista de contornos
        # Utilizamos la funci칩n max() con la clave (key) definida como el 치rea del contorno
        # Esto nos devuelve el contorno con el 치rea m치s grande
        contorno_principal = max(contours, key=cv2.contourArea)

        # Extraer los puntos del contorno principal
        # Esto selecciona las coordenadas (x, y) de cada punto del contorno principal y las guarda en contour_points
        contour_points = contorno_principal[:, 0, :]
        all_points_x = contour_points[:, 0] # CORDENADAS X
        all_points_y = contour_points[:, 1] # CORDENADAS Y

        #agrega una ultima cordenada para cerrar el poligono
        all_points_x = np.concatenate((all_points_x, [all_points_x[0]]))
        all_points_y = np.concatenate((all_points_y, [all_points_y[0]]))


        # AQUI se aumenta los bordes de la mascara resultante

        ##############################################################################
        # se estrae la dimenciones de las imagenes con el fin de poder limitar el tama침o de las mascaras evitando errores
        resized_image = cv2.imread(IMAGE_PATH)
        resized_height, resized_width = resized_image.shape[:2]

        # crea un objeto de pol칤gono a partir de las coordenadas x & y
        poligono_original = crear_polygon_desde_vectores(np.array(all_points_x), np.array(all_points_y))

				# Ajustar el tama침o y posici칩n del pol칤gono contenedor
        factor_agrandamiento = 4 #pixeles
        # Crear un pol칤gono contenedor alrededor del pol칤gono original, agrandado por el factor definido
        # Esto crea un nuevo pol칤gono que rodea el pol칤gono original con un borde adicional igual al factor de agrandamiento
        poligono_contenedor = poligono_original.buffer(factor_agrandamiento)
        # Extraer las coordenadas (x, y) de todos los puntos del pol칤gono contenedor
        # Esto devuelve una lista separada de las coordenadas x y y de todos los puntos que forman el contorno exterior del pol칤gono contenedor
        all_points_x_alejado, all_points_y_alejado = poligono_contenedor.exterior.xy

        # En caso de querer ajustar las etiquetas de las imagenes dezplazando en el eje x,y
        # En este ejemplo no es necesario
        desplazamiento_x=0
        desplazamiento_y=0
        # se realiza el desplazamiento de las etiquetas en ambos ejes de coordenadas
        all_points_x_desplazado = (np.array(all_points_x_alejado) - desplazamiento_x).tolist()
        all_points_y_desplazado = (np.array(all_points_y_alejado) - desplazamiento_y).tolist()

        # Aplicar la funci칩n np.clip() para limitar las coordenadas x e y dentro de los l칤mites de la imagen redimensionada
        # Esto asegura que todos los puntos del pol칤gono est칠n dentro de la imagen redimensionada
        # np.clip(a, a_min, a_max) limita los valores en el array 'a' entre 'a_min' y 'a_max'
        # En este caso, se limitan las coordenadas x e y a valores entre 0 y el ancho/redimensionado_width - 1, y alto/redimensionado_height - 1 respectivamente
        all_points_x_desplazado = np.clip(all_points_x_desplazado, 0, resized_width - 1).tolist()
        all_points_y_desplazado = np.clip(all_points_y_desplazado, 0, resized_height - 1).tolist()

        # umbral para evitar que los puntos est칠n demasiado cerca de los bordes de la imagen redimensionada
        umbral_distancia_bordes = 5 #pixeles

				# Ajustar las coordenadas x e y para evitar que los puntos est칠n demasiado cerca de los bordes de la imagen redimensionada
        # Esto se realiza para evitar que los puntos est칠n demasiado cerca de los bordes de la imagen,
        # lo que podr칤a causar problemas al dibujar el pol칤gono o realizar c치lculos adicionales.
        # Se utilizan comprensiones de listas para iterar sobre todas las coordenadas x e y y aplicar la funci칩n min() y max() para cada valor.
        all_points_x_desplazado = [min(resized_width - umbral_distancia_bordes, max(val, umbral_distancia_bordes)) for val in all_points_x_desplazado]
        all_points_y_desplazado = [min(resized_height - umbral_distancia_bordes, max(val, umbral_distancia_bordes)) for val in all_points_y_desplazado]

        # Redondear las coordenadas x e y a n칰meros enteros
        # Esto se hace para asegurar que todas las coordenadas sean enteras, ya que las coordenadas de p칤xeles deben ser n칰meros enteros.
        all_points_x_desplazado = list(map(round, all_points_x_desplazado, [1] * len(all_points_x_desplazado)))
        all_points_y_desplazado = list(map(round, all_points_y_desplazado, [1] * len(all_points_y_desplazado)))

        all_points_x = all_points_x_desplazado
        all_points_y = all_points_y_desplazado

        ##############################################################################
        # Estructura las mascaras en formato .json y las guarda bajo el nombre definido en 'CLASE' se puede excluir la ultima mascara
        # dependiendo de OP [0,1]
        if i < len(boxx)-OP:
            caja_con_mascara["regions"][f"{i}"] = {
                "shape_attributes": {
                    "name": "polygon",
                    "all_points_x": all_points_x,  # Convertir a lista si es necesario   .tolist()
                    "all_points_y": all_points_y   # Convertir a lista si es necesario  .tolist()
                },
                "region_attributes": {
                    "objetos": f"{os.path.basename(CLASE)}"
                }
            }
            # Grafica las mascaras de forma individual para una mejor supervision
            points_x.append(all_points_x)
            points_y.append(all_points_y)
            if ver==True:
                plt.figure(figsize=(3, 3))
                plt.plot(all_points_x, all_points_y, 'r-')
                plt.title(f"Contorno mancha {i}")
                plt.gca().invert_yaxis()
                plt.show()
        # Si OP=0 este escrip no se ejecuta ya que pertenece a la ultima etiqueta asignada a la clase 'HOJAS'
        elif i == len(boxx)-OP:
            caja_con_mascara["regions"][f"{i}"] = {
                "shape_attributes": {
                    "name": "polygon",
                    "all_points_x": all_points_x,  # Convertir a lista si es necesario  .tolist()
                    "all_points_y": all_points_y   # Convertir a lista si es necesario   .tolist()
                },
                "region_attributes": {
                    "objetos": 'HOJAS' #f"{os.path.basename(CLASE)}" #"HOJAS"
                }
            }
            # Esto se hace para almacenar las coordenadas x & y de cada punto del pol칤gono en listas separadas,
            # que luego se pueden utilizar para construir pol칤gonos compuestos.
            points_x.append(all_points_x)
            points_y.append(all_points_y)

            if ver==True:
                plt.figure(figsize=(3, 3))
                plt.plot(all_points_x, all_points_y, 'r-')
                plt.title('Contorno hoja')
                plt.gca().invert_yaxis()
                plt.show()

    # Concatenar las listas de puntos x e y en un 칰nico array
    # Esto se realiza para combinar todas las coordenadas x e y de los puntos del pol칤gono en un solo array.
    points_x = np.concatenate(points_x)
    points_y = np.concatenate(points_y)
    # Agregar una entrada al diccionario 'estructura_deseada'
    estructura_deseada[nombre_archivo] = caja_con_mascara
    # Grafica todas las mascaras creadas superpuesta a la imagen segmentada
    if ver==True:
        plt.figure(figsize=(10, 10))
        plt.plot(points_x, points_y, 'r.', markersize=2)
        plt.title('todos los contornos')
        plt.gca().invert_yaxis()
        image_bgr = cv2.imread(IMAGE_PATH)
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        plt.imshow(image_rgb)
        plt.show()

    print("conversion de fomarto hecho:"+f"{os.path.basename(CLASE)}")
    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)

    return estructura_deseada

def Elegir_IMAGEN(numero, carpeta_drive, nombre_imagen):

    """"
    En aplicaciones de procesamiento de im치genes, a veces es necesario seleccionar im치genes
    espec칤ficas de una carpeta para su an치lisis o manipulaci칩n posterior.
    Esta funci칩n se utiliza para seleccionar r치pidamente la imagen deseada en funci칩n de su nombre y n칰mero.

    esta funci칩n toma un n칰mero, una carpeta y un nombre de imagen como entrada,
    y selecciona una imagen espec칤fica de la carpeta bas치ndose en el n칰mero proporcionado
    y la estructura deseada del nombre de archivo.
    """
    # Obtener la lista de nombres de archivos en la carpeta
    nombres_archivos = os.listdir(carpeta_drive)
    # Filtrar los nombres de archivos para aquellos que coincidan con la estructura deseada
    # los archivos filtrados tienen una estructura "nombre_imagen2.jpg" "nombre_imagen3.jpg" .....
    archivos_deseados = [archivo for archivo in nombres_archivos if archivo.startswith(nombre_imagen) and archivo.endswith('.jpg')]
    # Ordenar la lista de archivos seg칰n su n칰mero
    archivos_deseados.sort(key=lambda x: int(x[len(nombre_imagen):-4]))
    # Obtener la ruta de la imagen deseada
    if 1 <= numero <= len(archivos_deseados):
        imagen_deseada = archivos_deseados[numero - 1]
        IMAGE_PATH = os.path.join(carpeta_drive, imagen_deseada)
        print("Ruta de la imagen deseada:", IMAGE_PATH)
    else:
        print("N칰mero fuera de rango.")

    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)
    return IMAGE_PATH

def GUARDAR_JSON(estructura_deseada, IMAGE_PATH,rutaJson):
    """"
    toma tres par치metros: estructura_deseada, IMAGE_PATH y rutaJson.
    La funci칩n tiene la tarea de guardar la estructura deseada en formato JSON en un archivo en la ruta especificada por rutaJson,
    utilizando el nombre de archivo de la imagen IMAGE_PATH como base para el nombre del archivo JSON.
    """
    # Extraer el nombre del archivo sin la extensi칩n
    nombre_sin_extension = os.path.splitext(os.path.basename(IMAGE_PATH))[0]
    # Construir la ruta completa para el archivo JSON a guardar
    ruta_del_archivo_json = f"{rutaJson +'/'}{nombre_sin_extension}.json"

    # Abrir el archivo JSON para escribir en 칠l
    with open(ruta_del_archivo_json, 'w') as archivo_json:
    # Se utiliza separators=(',', ':') para minimizar el tama침o del archivo JSON, eliminando espacios
    # y usando ':' como separador de clave-valor
    # Se utiliza indent=0 para que no se agregue sangr칤a en el archivo JSON, lo que reduce a칰n m치s su tama침o
        json.dump(estructura_deseada, archivo_json, separators=(',', ':'), indent=0)

    print("guardado en: " + ruta_del_archivo_json)

    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)


# Definir la zona horaria de Bogot치
zona_horaria_bogota = pytz.timezone("America/Bogota")
# Obtener la hora actual en la zona horaria de Bogot치
hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
# Imprimir la hora actual en Bogot치 en formato AM/PM
print("cargado: ", hora_actual_bogota)

"""### FORMATO DE SALIDA PARA SamAutomaticMaskGenerator

Esto describe la estructura de los datos devueltos por SamAutomaticMaskGenerator. Cada m치scara en la lista es un diccionario que contiene informaci칩n sobre la m치scara, como la m치scara en s칤, el 치rea, el cuadro delimitador, la predicci칩n de calidad del modelo, las coordenadas de puntos de entrada, la puntuaci칩n de estabilidad y la caja de recorte de la imagen.

SamAutomaticMaskGenerator devuelve una lista de m치scaras, donde cada m치scara es un diccionario que contiene varias informaciones sobre la m치scara:

- `segmentation` - `[np.ndarray]` - la m치scara con forma `(W, H)` y tipo `bool`
- `area` - `[int]` - el 치rea de la m치scara en p칤xeles
- `bbox` - `[List[int]]` - el cuadro delimitador de la m치scara en formato `xywh`
- `predicted_iou` - `[float]` - la predicci칩n del modelo sobre la calidad de la m치scara
- `point_coords` - `[List[List[float]]]` - el punto de entrada muestreado que gener칩 esta m치scara
- `stability_score` - `[float]` - una medida adicional de la calidad de la m치scara
- `crop_box` - `List[int]` - el recorte de la imagen utilizado para generar esta m치scara en formato `xywh`
"""

#print(sam_result[0].keys())

"""# LIBRERIAS, GOOGLE DRIVE Y MODELO"""

import os
from google.colab import drive
from datetime import datetime
import pytz
drive.mount('/content/drive')
mask_predictor = SamPredictor(sam)

"""# SELECI칍N DE IMAGENES PARA ETIQUETADO

Toma un n칰mero, una carpeta y un nombre de imagen como entrada, y selecciona una imagen espec칤fica de la carpeta bas치ndose en el n칰mero proporcionado y la estructura deseada del nombre de archivo.

Es importante que la carpeta en donde van estar almacenadas las imagenes en formato `.jpg ` tengan una estructura de los nombres donde: `nombre_imagen`+`numero`+`.jpg`

ANCLA
print('<a name="mi_seccion"></a>')
"""

import os
# escoge la carpeta donde se encuentran las imagenes de val train o test
carpeta_drive = '/content/drive/MyDrive/FALTANTES/MINADOR'
# escoger la ruta de guardado del archivo .json
rutaJson='/content/drive/MyDrive/FALTANTES/ETIQUETA FALTANTE MINADOR'
# se escoge la clase, en este caso la enfermedad de las hojas
# CLASE=[SANAS ROYA COCO MINADOR] (EJEMPLOS)
CLASE="MINADOR"
# nombre_imagen (EJEMPLOS)
#'COCO_M_A_' , 'COCO_Muy_A_' , 'COCO_P_A_' , 'COCO_RECORTE_'
#'MINEIRO_' , 'MINADOR_' , 'MINADO_RECORTES'
#'ROYA_FONDO_' , 'ROYA_M_A_' , 'ROYA_Muy_A_' , 'ROYA_P_A_' , 'ROYA_RECORTES'
#'SANAS_NUEVAS_' 'SANAS_ROCOLE_' 'SANAS_SOCORRO_'
nombre_imagen='MINADO_RECORTES_'
################################################################################
numero = 1 # <------------------Tu n칰mero espec칤fico
################################################################################
IMAGE_PATH=Elegir_IMAGEN(numero,carpeta_drive, nombre_imagen)

"""# GENERAR SEGMENTACI칍N CON CUADRO DELIMITADOR

La clase `SamPredictor` proporciona una interfaz sencilla al modelo para solicitar predicciones al modelo. Permite al usuario primero establecer una imagen utilizando el m칠todo `set_image`, que calcula los embebidos de imagen necesarios. Luego, se pueden proporcionar indicaciones a trav칠s del m칠todo `predict` para predecir eficientemente m치scaras a partir de esas indicaciones. El modelo puede tomar como entrada tanto indicaciones de puntos y cuadros delimitadores como m치scaras de la iteraci칩n anterior de predicci칩n.

### Draw Box

**NOTE:** Ejecute la celda siguiente y utilice su rat칩n para dibujar un cuadro delimitador en la imagen. 游녢
"""

# helper function that loads an image before adding it to the widget
import base64
def encode_image(filepath):
    with open(filepath, 'rb') as f:
        image_bytes = f.read()
    encoded = str(base64.b64encode(image_bytes), 'utf-8')
    return "data:image/jpg;base64,"+encoded
IS_COLAB = True

if IS_COLAB:
    from google.colab import output
    output.enable_custom_widget_manager()

from jupyter_bbox_widget import BBoxWidget

widget = BBoxWidget()
widget.image = encode_image(IMAGE_PATH)
widget

# widget.bboxes

"""### Generate masks with SAM

**NOTE:** `SamPredictor.predict` method takes `np.ndarray` `box` argument in `[x_min, y_min, x_max, y_max]` format. Let's reorganise your data first

#**(IMPORTANTE) ESCOGER: OP  VALOR DE 0, 1**

# **ACUMULAR MASCARAS**

Procesa una imagen segmentando las 치reas de inter칠s definidas por las cajas delimitadoras y acumula las m치scaras resultantes. La opci칩n `OP` permite controlar si se incluye o no la 칰ltima m치scara en el resultado final.
"""

OP=0 # <------------ OP=0 ETIQUETA TODAS CON LA MISMA CLASE #OP=1  LA ULTIMA ETIQUETA TIENE COMO CLASE 'HOJAS'

scoress, logitss, maskss, cumulative_mask, boxx = procesar_imagen(IMAGE_PATH, widget, mask_predictor, OP)
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
dibujar_cajas(IMAGE_PATH, widget.bboxes)

"""# ESCOGER OPCIONES DE MASCARAS

La funci칩n devuelve tres opciones por regi칩n de box porque est치 configurando el par치metro multimask_output en True, recibiendo m칰ltiples m치scaras como salida para cada regi칩n delimitada por las cajas proporcionadas.
"""

import matplotlib.pyplot as plt
plot_binary_masks(cumulative_mask)

"""AHORA ESCOGES LA OPCION MAS ADECUADA"""

OPCION=2
plot_binary_mask2(cumulative_mask[OPCION-1], title='MASCARA ELEGIDA')

OPCION2=2

"""---

### SOLO VALIDO CUANDO SE VA A SEGMENTAR HOJAS ENFERMAS
"""

#SOLO PARA HOJAS ENFERMAS
plot_binary_masks(maskss[len(boxx)-OP])

"""---

---

### SOLO VALIDO CUANDO SE VA A SEGMENTAR HOJAS ENFERMAS
"""

#SOLO PARA HOJAS ENFERMAS
OPCION2=2
plot_binary_mask2(maskss[len(boxx)-OP][OPCION2-1], title='MASCARA ELEGIDA')

"""---

# A) ACTUALIZAR LISTAS DE MASCARAS DEACUERDO A LAS OPCIONES ELEGIDAS
"""

lista_de_mascaras=ACTUALIZAR_MASK(boxx, mask_predictor,  OP, OPCION, OPCION2)

"""# B)  CONVIERTE LAS MASKCARAS EN FORMATO .JSON"""

# para quitar grafica ver=False
estructura_deseada = convertir_JSON(boxx, IMAGE_PATH, widget, lista_de_mascaras, CLASE, OP, ver=True)

"""## C) **GUARDA EL ARCHIVO EN FORMATO .JSON**"""

GUARDAR_JSON(estructura_deseada, IMAGE_PATH,rutaJson)

"""print('[Ir a mi secci칩n](#mi_seccion)')

---

---

---
"""