# -*- coding: utf-8 -*-
"""TESIS_SAM_segment_anything.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/128oBM5l8fQbyK8xQjjWPVj-mb0pgz3nL

# Model Segment Anything (SAM), UNA OPCION INTERESANTE PARA ETIQUETADO DE MASCARAS UTILIZADOS EN ENTRENAMIENTOS BASADOS EN SEGMENTACIÓN SEMANTICA.

---

Modelo Segment Anything (SAM): un nuevo modelo de IA de Meta AI que puede "recortar" cualquier objeto, en cualquier imagen, con un solo clic. SAM es un sistema de segmentación que se puede solicitar con generalización de cero disparos a objetos e imágenes desconocidos, sin necesidad de entrenamiento adicional. Este cuaderno es una extensión del [cuaderno oficial](https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb) preparado por Meta AI.

El Modelo Segment Anything (SAM) representa una opción altamente prometedora en el ámbito del etiquetado de máscaras utilizado en entrenamientos basados en segmentación semántica. SAM ofrece una solución avanzada y versátil para la tarea crucial de segmentación de imágenes, permitiendo a los investigadores y practicantes del aprendizaje automático abordar una amplia gama de aplicaciones de manera efectiva. Esta introducción explorará cómo SAM se destaca como una herramienta integral y eficiente para la generación de máscaras precisas y detalladas, allanando el camino para avances significativos en la comprensión y manipulación de datos visuales.

![modelo segment anything](https://media.roboflow.com/notebooks/examples/segment-anything-model-paper.png)
## SAM como una herramienta semi-asistida
 se podría considerar a SAM como una herramienta semi-asistida para el etiquetado de imágenes en el contexto de tareas de segmentación. Aunque SAM no es un etiquetador en sí mismo, sino un modelo de segmentación, puede facilitar significativamente el proceso de etiquetado proporcionando predicciones precisas de máscaras para las imágenes. Esto puede ayudar a los usuarios a realizar el etiquetado de manera más eficiente al reducir la carga manual de generar máscaras para segmentar objetos en las imágenes. Sin embargo, aún requiere la interacción humana para proporcionar las cajas delimitadoras o indicaciones necesarias para generar las máscaras.

## Consejo profesional: Utiliza la Aceleración de GPU

Si estás ejecutando este cuaderno en Google Colab, ve a `Editar` -> `Configuración del cuaderno` -> `Acelerador de hardware`, configúralo en `GPU` y luego haz clic en `Guardar`. Esto asegurará que tu cuaderno utilice una GPU, lo que acelerará significativamente los tiempos de entrenamiento del modelo.

## Pasos en este Tutorial

En este tutorial, vamos a cubrir:

- **Antes de empezar** - Asegúrate de tener acceso a la GPU
- Instalar el Modelo Segment Anything (SAM)
- Cargar el Modelo
- Generación Automática de Máscaras
- Generar Segmentación con Cuadro delimitador
- Segmentar Cualquier Cosa en el Conjunto de Datos del Universo Roboflow

## ¡Comencemos!

## Antes de empezar

Asegurémonos de tener acceso a la GPU. Podemos usar el comando `nvidia-smi` para hacerlo. En caso de cualquier problema, navega a `Editar` -> `Configuración del cuaderno` -> `Acelerador de hardware`, configúralo en `GPU` y luego haz clic en `Guardar`.
"""

!nvidia-smi

"""Este código cambia al directorio actual, instala el modelo SAM y sus dependencias utilizando pip, y muestra el directorio actual antes de realizar la instalación.

NOTA: Para facilitarnos la gestión de conjuntos de datos, imágenes y modelos que creamos, creamos una constante llamada `HOME`.
"""

# Commented out IPython magic to ensure Python compatibility.
import os
# El directorio de trabajo actual es el directorio desde el cual se está ejecutando el script o el programa en ese momento.
HOME = os.getcwd()
print("HOME:", HOME)
#Install Segment Anything Model (SAM) and other dependencies
# %cd {HOME}
import sys
!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'

"""Se instala los paquetes que roporcionan herramientas y utilidades útiles para el desarrollo de proyectos de visión por computadora y aprendizaje automático en entornos de `Jupyter Notebooks`. `jupyter_bbox_widget` ofrece un widget interactivo para trabajar con cuadros delimitadores en imágenes dentro de los notebooks. `roboflow` facilita tareas de preprocesamiento, aumento y conversión de conjuntos de datos de visión por computadora. `dataclasses-json` simplifica la serialización y deserialización de objetos de datos definidos por el usuario a/desde JSON. Por último, `supervision*` proporciona herramientas para la gestión y supervisión de tareas de aprendizaje automático, como entrenamiento y evaluación de modelos, así como gestión de conjuntos de datos."""

!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision

"""### DESCARGAR PESOS"""

# Commented out IPython magic to ensure Python compatibility.
# Cambiar al directorio HOME
# %cd {HOME}
# Crear un directorio llamado "weights" dentro del directorio HOME
!mkdir {HOME}/weights
# Cambiar al directorio "weights" recién creado
# %cd {HOME}/weights
# El modelo se descarga desde una URL específica y se almacena en el directorio "weights"
!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth
# Importar el módulo os para trabajar con rutas de archivo y directorio
import os
# Crear la ruta completa al archivo de punto de control (checkpoint) descargado
CHECKPOINT_PATH = os.path.join(HOME, "weights", "sam_vit_h_4b8939.pth")
# Imprimir la ruta completa del archivo de punto de control y verificar si existe
print(CHECKPOINT_PATH, "; exist:", os.path.isfile(CHECKPOINT_PATH))

"""## CARGAR MODELO"""

# Importar la biblioteca PyTorch
import torch
# Determinar el dispositivo de cómputo (GPU o CPU) disponible
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
# Definir el tipo de modelo a utilizar
MODEL_TYPE = "vit_h"
# Importar las clases y funciones necesarias de la biblioteca "segment_anything"
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
# Crear una instancia del modelo SAM correspondiente al tipo de modelo especificado
# Se carga el modelo previamente descargado (CHECKPOINT_PATH) y se mueve al dispositivo disponible (DEVICE)
sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)

"""# **CARGAR FUNCIONES PARA GRAFICAR MASCARAS, CAJAS Y SELECCION DE IMAGENES A ETIQUETAR**"""

import matplotlib.pyplot as plt
import json
import numpy as np
import os
from scipy.spatial import ConvexHull
import cv2
import matplotlib.patches as patches
import supervision as sv
from datetime import datetime
import pytz


def plot_binary_masks(mask_set):
    """" Esta función toma un conjunto de máscaras binarias como entrada y las visualiza en una cuadrícula de subgráficos.
         Cada máscara se muestra en su propio subplot con un título correspondiente, y los ejes se ocultan para una presentación
         más limpia.
    """
    # Obtener el número de máscaras en el conjunto
    num_masks = len(mask_set)
    # Definir el número de columnas para organizar las máscaras en la visualización
    cols = 3  # Puedes ajustar el número de columnas según tu preferencia
    # Calcular el número de filas necesario para acomodar todas las máscaras
    rows = (num_masks + cols - 1) // cols
    # Configurar el tamaño de la figura
    plt.figure(figsize=(15, 5 * rows))
    # Iterar sobre cada máscara en el conjunto
    for i, mask in enumerate(mask_set, 1):
        # Crear un subplot correspondiente a cada máscara
        plt.subplot(rows, cols, i)
        # Mostrar la máscara en el subplot actual
        plt.imshow(mask, cmap='binary')
        # Configurar el título del subplot
        plt.title(f'Mask OPCION {i}')
        # Ocultar los ejes en el subplot
        plt.axis('off')
    plt.show()

# funcion que imprime la mascara de la hoja individual.
def plot_binary_mask2(mask, title='Mask'):
    plt.figure(figsize=(11, 11))
    plt.imshow(mask, cmap='binary')
    plt.title(title)
    plt.axis('off')
    plt.show()


def dibujar_cajas(image_path, cajas):
    """" muestra una imagen (seleccion de la etiqueta del objeto a segmentar) con las cajas delimitadoras superpuestas en ella
         lo que es util para mostrar las cajas seleccionadas
    """
    # Leer la imagen
    image_bgr = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    # Crear una figura y un conjunto de ejes
    #plt.figure(figsize=(10, 10))
    fig, ax = plt.subplots(figsize=(10, 10))
    # Mostrar la imagen
    ax.imshow(image_rgb)
    # Iterar sobre las cajas y dibujarlas en la imagen
    for box in cajas:
        x, y, w, h = box['x'], box['y'], box['width'], box['height']
        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
    # Mostrar la imagen con las cajas
    plt.show()



def procesar_imagen(IMAGE_PATH, widget, mask_predictor,  OP):
    """"
        Esta función procesar_imagen toma como entrada la ruta de la imagen (IMAGE_PATH),
        un widget que contiene las cajas delimitadoras seleccionadas (widget),
        un objeto que representa el modelo de predicción de máscaras (mask_predictor),
        y una opción OP que determina si se debe incluir o no la última máscara en el resultado final.

        Esta función procesa una imagen segmentando las áreas de interés definidas por las cajas delimitadoras
        y acumula las máscaras resultantes. La opción OP permite controlar si se incluye o no la última máscara
        en el resultado final.
    """
    boxx = []

    # Recorrer las cajas y construir un array con las coordenadas
    for i in range(len(widget.bboxes)):
        box = widget.bboxes[i]
        boxx.append(np.array([
            box['x'],
            box['y'],
            box['x'] + box['width'],
            box['y'] + box['height']
        ]))

    # Leer la imagen
    image_bgr = cv2.imread(IMAGE_PATH)
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    #  prepara el modelo para procesar la imagen image_rgb.
    mask_predictor.set_image(image_rgb)
    # crea una matriz de ceros con el mismo tamaño de la imagen RGB, cada elemento de la matriz representa un entero sin signo de 8 bits.
    # Esta matriz se utilizará posteriormente para acumular las máscaras de segmentación resultantes.
    cumulative_mask = np.zeros_like(image_rgb[:, :, 0], dtype=np.uint8)

    scoress = []
    logitss = []
    maskss = []
    # este bucle procesa todas las cajas delimitadoras, predice las máscaras correspondientes
    # y acumula las máscaras predichas según el valor de OP.
    for i in range(len(boxx)):
        masks, scores, logits = mask_predictor.predict(
            box=boxx[i],
            multimask_output=True
        )

        if i < len(boxx) - OP:
            cumulative_mask = cumulative_mask | masks

        scoress.append(scores)
        logitss.append(logits)
        maskss.append(masks)

    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)

    return scoress, logitss, maskss, cumulative_mask, boxx

def ACTUALIZAR_MASK(boxx, mask_predictor,  OP=1, OPCION=2,OPCION2=2):
    """" Esta función toma una lista de cajas delimitadoras (boxx), un predictor de máscaras (mask_predictor),
         y varios parámetros (OP, OPCION, OPCION2) para actualizar las máscaras asociadas con las regiones de interés
         definidas por las cajas delimitadoras. La función devuelve una lista de máscaras actualizadas
         y proporciona información sobre el número de máscaras
    """
    lista_de_mascaras = []
    # Iterar sobre cada caja delimitadora en la lista boxx
    for i in range(len(boxx)):
        # Predecir la máscara correspondiente a la región de interés definida por la caja delimitadora
        masks, scores, logits = mask_predictor.predict(
            box=boxx[i],
            multimask_output=True
        )
        # Dependiendo de la opcion incluye o excluye la ultima etiqueta con el fin de tener una mejor visulizacion
        # de las etiquetas
        if i < len(boxx)-OP:
            lista_de_mascaras.append(masks[OPCION-1])
        elif i == len(boxx)-OP:
            lista_de_mascaras.append(masks[OPCION2-1])

    print(f"{'Numero de Box:'}{len(lista_de_mascaras)}")
    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)
    return lista_de_mascaras

from shapely.geometry import Polygon

def crear_polygon_desde_vectores( x, y):
    """" Esta función proporciona una forma conveniente de crear un objeto de polígono
        a partir de las coordenadas de los vértices del polígono.
    """
    # Combinar las coordenadas x e y en un array bidimensional
    coordenadas = np.column_stack((x, y))
    # Crear un objeto de polígono utilizando las coordenadas
    return Polygon(coordenadas)

################################################################################
# ESTRUCTURA DEL FORMATO .JSON ADAPTADO PARA UTILIZAR LA HERRAMIENTA DE (VGG)
# https://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.0.html

       # Load annotations
        # VGG Image Annotator saves each image in the form:
        # { 'filename': 'IMAGEN.jpg',
        #   'regions': {
        #       '0': {
        #           'region_attributes': {},
        #           'shape_attributes': {
        #               'all_points_x': [...],
        #               'all_points_y': [...],
        #               'name': 'polygon'}},
        #       ... more regions ...
        #   },
        #   'size': 80202
        # }
        # We mostly care about the x and y coordinates of each region
################################################################################

def convertir_JSON(boxx, IMAGE_PATH, widget, lista_de_mascaras, CLASE, OP,ver):
    # Crear el nombre del archivo
    points_x=[]
    points_y=[]
    # define el nombre de archivo  en formato .json apartir del nombre de la imagen
    nombre_archivo = f"{os.path.basename(IMAGE_PATH)}{os.path.getsize(IMAGE_PATH)}"
    caja_con_mascara = {
        "fileref": "",
        "size": os.path.getsize(IMAGE_PATH),  # Ajusta el tamaño según tus necesidades
        "filename": nombre_archivo,  # Ajusta el formato del nombre del archivo
        "base64_img_data": "",
        "file_attributes": {},
        "regions": {}
    }
    # Cajas y las máscaras en listas separadas
    lista_de_cajas = widget.bboxes
    # Crear la estructura deseada
    estructura_deseada = {}
    # Agregar las regiones al diccionario
    for i, mascara in enumerate(lista_de_mascaras):
        binary_image=lista_de_mascaras[i]
        # Convertir la imagen binaria a una imagen con valores 0 y 255 (negro y blanco)
        binary_image_as_uint8 = binary_image.astype(np.uint8) * 255

        # Crear una imagen en blanco
        height, width = binary_image.shape
        image = np.zeros((height, width, 3), dtype=np.uint8)

        # Obtener las coordenadas (índices) donde los valores son True
        indices_true = np.where(binary_image)

        # Crear una lista de puntos (x, y) a partir de las coordenadas
        points = np.column_stack((indices_true[1], indices_true[0]))

        # Dibujar el polígono en la imagen en blanco
        cv2.fillPoly(image, [points], color=(255, 255, 255))

        # Encontrar los contornos en la imagen binaria original
        # cv2.findContours() devuelve una lista de contornos
        contours, _ = cv2.findContours(binary_image_as_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Encontrar el contorno principal dentro de la lista de contornos
        # Utilizamos la función max() con la clave (key) definida como el área del contorno
        # Esto nos devuelve el contorno con el área más grande
        contorno_principal = max(contours, key=cv2.contourArea)

        # Extraer los puntos del contorno principal
        # Esto selecciona las coordenadas (x, y) de cada punto del contorno principal y las guarda en contour_points
        contour_points = contorno_principal[:, 0, :]
        all_points_x = contour_points[:, 0] # CORDENADAS X
        all_points_y = contour_points[:, 1] # CORDENADAS Y

        #agrega una ultima cordenada para cerrar el poligono
        all_points_x = np.concatenate((all_points_x, [all_points_x[0]]))
        all_points_y = np.concatenate((all_points_y, [all_points_y[0]]))


        # AQUI se aumenta los bordes de la mascara resultante

        ##############################################################################
        # se estrae la dimenciones de las imagenes con el fin de poder limitar el tamaño de las mascaras evitando errores
        resized_image = cv2.imread(IMAGE_PATH)
        resized_height, resized_width = resized_image.shape[:2]

        # crea un objeto de polígono a partir de las coordenadas x & y
        poligono_original = crear_polygon_desde_vectores(np.array(all_points_x), np.array(all_points_y))

				# Ajustar el tamaño y posición del polígono contenedor
        factor_agrandamiento = 4 #pixeles
        # Crear un polígono contenedor alrededor del polígono original, agrandado por el factor definido
        # Esto crea un nuevo polígono que rodea el polígono original con un borde adicional igual al factor de agrandamiento
        poligono_contenedor = poligono_original.buffer(factor_agrandamiento)
        # Extraer las coordenadas (x, y) de todos los puntos del polígono contenedor
        # Esto devuelve una lista separada de las coordenadas x y y de todos los puntos que forman el contorno exterior del polígono contenedor
        all_points_x_alejado, all_points_y_alejado = poligono_contenedor.exterior.xy

        # En caso de querer ajustar las etiquetas de las imagenes dezplazando en el eje x,y
        # En este ejemplo no es necesario
        desplazamiento_x=0
        desplazamiento_y=0
        # se realiza el desplazamiento de las etiquetas en ambos ejes de coordenadas
        all_points_x_desplazado = (np.array(all_points_x_alejado) - desplazamiento_x).tolist()
        all_points_y_desplazado = (np.array(all_points_y_alejado) - desplazamiento_y).tolist()

        # Aplicar la función np.clip() para limitar las coordenadas x e y dentro de los límites de la imagen redimensionada
        # Esto asegura que todos los puntos del polígono estén dentro de la imagen redimensionada
        # np.clip(a, a_min, a_max) limita los valores en el array 'a' entre 'a_min' y 'a_max'
        # En este caso, se limitan las coordenadas x e y a valores entre 0 y el ancho/redimensionado_width - 1, y alto/redimensionado_height - 1 respectivamente
        all_points_x_desplazado = np.clip(all_points_x_desplazado, 0, resized_width - 1).tolist()
        all_points_y_desplazado = np.clip(all_points_y_desplazado, 0, resized_height - 1).tolist()

        # umbral para evitar que los puntos estén demasiado cerca de los bordes de la imagen redimensionada
        umbral_distancia_bordes = 5 #pixeles

				# Ajustar las coordenadas x e y para evitar que los puntos estén demasiado cerca de los bordes de la imagen redimensionada
        # Esto se realiza para evitar que los puntos estén demasiado cerca de los bordes de la imagen,
        # lo que podría causar problemas al dibujar el polígono o realizar cálculos adicionales.
        # Se utilizan comprensiones de listas para iterar sobre todas las coordenadas x e y y aplicar la función min() y max() para cada valor.
        all_points_x_desplazado = [min(resized_width - umbral_distancia_bordes, max(val, umbral_distancia_bordes)) for val in all_points_x_desplazado]
        all_points_y_desplazado = [min(resized_height - umbral_distancia_bordes, max(val, umbral_distancia_bordes)) for val in all_points_y_desplazado]

        # Redondear las coordenadas x e y a números enteros
        # Esto se hace para asegurar que todas las coordenadas sean enteras, ya que las coordenadas de píxeles deben ser números enteros.
        all_points_x_desplazado = list(map(round, all_points_x_desplazado, [1] * len(all_points_x_desplazado)))
        all_points_y_desplazado = list(map(round, all_points_y_desplazado, [1] * len(all_points_y_desplazado)))

        all_points_x = all_points_x_desplazado
        all_points_y = all_points_y_desplazado

        ##############################################################################
        # Estructura las mascaras en formato .json y las guarda bajo el nombre definido en 'CLASE' se puede excluir la ultima mascara
        # dependiendo de OP [0,1]
        if i < len(boxx)-OP:
            caja_con_mascara["regions"][f"{i}"] = {
                "shape_attributes": {
                    "name": "polygon",
                    "all_points_x": all_points_x,  # Convertir a lista si es necesario   .tolist()
                    "all_points_y": all_points_y   # Convertir a lista si es necesario  .tolist()
                },
                "region_attributes": {
                    "objetos": f"{os.path.basename(CLASE)}"
                }
            }
            # Grafica las mascaras de forma individual para una mejor supervision
            points_x.append(all_points_x)
            points_y.append(all_points_y)
            if ver==True:
                plt.figure(figsize=(3, 3))
                plt.plot(all_points_x, all_points_y, 'r-')
                plt.title(f"Contorno mancha {i}")
                plt.gca().invert_yaxis()
                plt.show()
        # Si OP=0 este escrip no se ejecuta ya que pertenece a la ultima etiqueta asignada a la clase 'HOJAS'
        elif i == len(boxx)-OP:
            caja_con_mascara["regions"][f"{i}"] = {
                "shape_attributes": {
                    "name": "polygon",
                    "all_points_x": all_points_x,  # Convertir a lista si es necesario  .tolist()
                    "all_points_y": all_points_y   # Convertir a lista si es necesario   .tolist()
                },
                "region_attributes": {
                    "objetos": 'HOJAS' #f"{os.path.basename(CLASE)}" #"HOJAS"
                }
            }
            # Esto se hace para almacenar las coordenadas x & y de cada punto del polígono en listas separadas,
            # que luego se pueden utilizar para construir polígonos compuestos.
            points_x.append(all_points_x)
            points_y.append(all_points_y)

            if ver==True:
                plt.figure(figsize=(3, 3))
                plt.plot(all_points_x, all_points_y, 'r-')
                plt.title('Contorno hoja')
                plt.gca().invert_yaxis()
                plt.show()

    # Concatenar las listas de puntos x e y en un único array
    # Esto se realiza para combinar todas las coordenadas x e y de los puntos del polígono en un solo array.
    points_x = np.concatenate(points_x)
    points_y = np.concatenate(points_y)
    # Agregar una entrada al diccionario 'estructura_deseada'
    estructura_deseada[nombre_archivo] = caja_con_mascara
    # Grafica todas las mascaras creadas superpuesta a la imagen segmentada
    if ver==True:
        plt.figure(figsize=(10, 10))
        plt.plot(points_x, points_y, 'r.', markersize=2)
        plt.title('todos los contornos')
        plt.gca().invert_yaxis()
        image_bgr = cv2.imread(IMAGE_PATH)
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        plt.imshow(image_rgb)
        plt.show()

    print("conversion de fomarto hecho:"+f"{os.path.basename(CLASE)}")
    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)

    return estructura_deseada

def Elegir_IMAGEN(numero, carpeta_drive, nombre_imagen):

    """"
    En aplicaciones de procesamiento de imágenes, a veces es necesario seleccionar imágenes
    específicas de una carpeta para su análisis o manipulación posterior.
    Esta función se utiliza para seleccionar rápidamente la imagen deseada en función de su nombre y número.

    esta función toma un número, una carpeta y un nombre de imagen como entrada,
    y selecciona una imagen específica de la carpeta basándose en el número proporcionado
    y la estructura deseada del nombre de archivo.
    """
    # Obtener la lista de nombres de archivos en la carpeta
    nombres_archivos = os.listdir(carpeta_drive)
    # Filtrar los nombres de archivos para aquellos que coincidan con la estructura deseada
    # los archivos filtrados tienen una estructura "nombre_imagen2.jpg" "nombre_imagen3.jpg" .....
    archivos_deseados = [archivo for archivo in nombres_archivos if archivo.startswith(nombre_imagen) and archivo.endswith('.jpg')]
    # Ordenar la lista de archivos según su número
    archivos_deseados.sort(key=lambda x: int(x[len(nombre_imagen):-4]))
    # Obtener la ruta de la imagen deseada
    if 1 <= numero <= len(archivos_deseados):
        imagen_deseada = archivos_deseados[numero - 1]
        IMAGE_PATH = os.path.join(carpeta_drive, imagen_deseada)
        print("Ruta de la imagen deseada:", IMAGE_PATH)
    else:
        print("Número fuera de rango.")

    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)
    return IMAGE_PATH

def GUARDAR_JSON(estructura_deseada, IMAGE_PATH,rutaJson):
    """"
    toma tres parámetros: estructura_deseada, IMAGE_PATH y rutaJson.
    La función tiene la tarea de guardar la estructura deseada en formato JSON en un archivo en la ruta especificada por rutaJson,
    utilizando el nombre de archivo de la imagen IMAGE_PATH como base para el nombre del archivo JSON.
    """
    # Extraer el nombre del archivo sin la extensión
    nombre_sin_extension = os.path.splitext(os.path.basename(IMAGE_PATH))[0]
    # Construir la ruta completa para el archivo JSON a guardar
    ruta_del_archivo_json = f"{rutaJson +'/'}{nombre_sin_extension}.json"

    # Abrir el archivo JSON para escribir en él
    with open(ruta_del_archivo_json, 'w') as archivo_json:
    # Se utiliza separators=(',', ':') para minimizar el tamaño del archivo JSON, eliminando espacios
    # y usando ':' como separador de clave-valor
    # Se utiliza indent=0 para que no se agregue sangría en el archivo JSON, lo que reduce aún más su tamaño
        json.dump(estructura_deseada, archivo_json, separators=(',', ':'), indent=0)

    print("guardado en: " + ruta_del_archivo_json)

    zona_horaria_bogota = pytz.timezone("America/Bogota")
    hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
    print("cargado: ", hora_actual_bogota)


# Definir la zona horaria de Bogotá
zona_horaria_bogota = pytz.timezone("America/Bogota")
# Obtener la hora actual en la zona horaria de Bogotá
hora_actual_bogota = datetime.now(zona_horaria_bogota).strftime("%I:%M %p")
# Imprimir la hora actual en Bogotá en formato AM/PM
print("cargado: ", hora_actual_bogota)

"""### FORMATO DE SALIDA PARA SamAutomaticMaskGenerator

Esto describe la estructura de los datos devueltos por SamAutomaticMaskGenerator. Cada máscara en la lista es un diccionario que contiene información sobre la máscara, como la máscara en sí, el área, el cuadro delimitador, la predicción de calidad del modelo, las coordenadas de puntos de entrada, la puntuación de estabilidad y la caja de recorte de la imagen.

SamAutomaticMaskGenerator devuelve una lista de máscaras, donde cada máscara es un diccionario que contiene varias informaciones sobre la máscara:

- `segmentation` - `[np.ndarray]` - la máscara con forma `(W, H)` y tipo `bool`
- `area` - `[int]` - el área de la máscara en píxeles
- `bbox` - `[List[int]]` - el cuadro delimitador de la máscara en formato `xywh`
- `predicted_iou` - `[float]` - la predicción del modelo sobre la calidad de la máscara
- `point_coords` - `[List[List[float]]]` - el punto de entrada muestreado que generó esta máscara
- `stability_score` - `[float]` - una medida adicional de la calidad de la máscara
- `crop_box` - `List[int]` - el recorte de la imagen utilizado para generar esta máscara en formato `xywh`
"""

#print(sam_result[0].keys())

"""# LIBRERIAS, GOOGLE DRIVE Y MODELO"""

import os
from google.colab import drive
from datetime import datetime
import pytz
drive.mount('/content/drive')
mask_predictor = SamPredictor(sam)

"""# SELECIÓN DE IMAGENES PARA ETIQUETADO

Toma un número, una carpeta y un nombre de imagen como entrada, y selecciona una imagen específica de la carpeta basándose en el número proporcionado y la estructura deseada del nombre de archivo.

Es importante que la carpeta en donde van estar almacenadas las imagenes en formato `.jpg ` tengan una estructura de los nombres donde: `nombre_imagen`+`numero`+`.jpg`

ANCLA
print('<a name="mi_seccion"></a>')
"""

import os
# escoge la carpeta donde se encuentran las imagenes de val train o test
carpeta_drive = '/content/drive/MyDrive/FALTANTES/MINADOR'
# escoger la ruta de guardado del archivo .json
rutaJson='/content/drive/MyDrive/FALTANTES/ETIQUETA FALTANTE MINADOR'
# se escoge la clase, en este caso la enfermedad de las hojas
# CLASE=[SANAS ROYA COCO MINADOR] (EJEMPLOS)
CLASE="MINADOR"
# nombre_imagen (EJEMPLOS)
#'COCO_M_A_' , 'COCO_Muy_A_' , 'COCO_P_A_' , 'COCO_RECORTE_'
#'MINEIRO_' , 'MINADOR_' , 'MINADO_RECORTES'
#'ROYA_FONDO_' , 'ROYA_M_A_' , 'ROYA_Muy_A_' , 'ROYA_P_A_' , 'ROYA_RECORTES'
#'SANAS_NUEVAS_' 'SANAS_ROCOLE_' 'SANAS_SOCORRO_'
nombre_imagen='MINADO_RECORTES_'
################################################################################
numero = 1 # <------------------Tu número específico
################################################################################
IMAGE_PATH=Elegir_IMAGEN(numero,carpeta_drive, nombre_imagen)

"""# GENERAR SEGMENTACIÓN CON CUADRO DELIMITADOR

La clase `SamPredictor` proporciona una interfaz sencilla al modelo para solicitar predicciones al modelo. Permite al usuario primero establecer una imagen utilizando el método `set_image`, que calcula los embebidos de imagen necesarios. Luego, se pueden proporcionar indicaciones a través del método `predict` para predecir eficientemente máscaras a partir de esas indicaciones. El modelo puede tomar como entrada tanto indicaciones de puntos y cuadros delimitadores como máscaras de la iteración anterior de predicción.

### Draw Box

**NOTE:** Ejecute la celda siguiente y utilice su ratón para dibujar un cuadro delimitador en la imagen. 👇
"""

# helper function that loads an image before adding it to the widget
import base64
def encode_image(filepath):
    with open(filepath, 'rb') as f:
        image_bytes = f.read()
    encoded = str(base64.b64encode(image_bytes), 'utf-8')
    return "data:image/jpg;base64,"+encoded
IS_COLAB = True

if IS_COLAB:
    from google.colab import output
    output.enable_custom_widget_manager()

from jupyter_bbox_widget import BBoxWidget

widget = BBoxWidget()
widget.image = encode_image(IMAGE_PATH)
widget

# widget.bboxes

"""### Generate masks with SAM

**NOTE:** `SamPredictor.predict` method takes `np.ndarray` `box` argument in `[x_min, y_min, x_max, y_max]` format. Let's reorganise your data first

#**(IMPORTANTE) ESCOGER: OP  VALOR DE 0, 1**

# **ACUMULAR MASCARAS**

Procesa una imagen segmentando las áreas de interés definidas por las cajas delimitadoras y acumula las máscaras resultantes. La opción `OP` permite controlar si se incluye o no la última máscara en el resultado final.
"""

OP=0 # <------------ OP=0 ETIQUETA TODAS CON LA MISMA CLASE #OP=1  LA ULTIMA ETIQUETA TIENE COMO CLASE 'HOJAS'

scoress, logitss, maskss, cumulative_mask, boxx = procesar_imagen(IMAGE_PATH, widget, mask_predictor, OP)
import cv2
import matplotlib.pyplot as plt
import matplotlib.patches as patches
dibujar_cajas(IMAGE_PATH, widget.bboxes)

"""# ESCOGER OPCIONES DE MASCARAS

La función devuelve tres opciones por región de box porque está configurando el parámetro multimask_output en True, recibiendo múltiples máscaras como salida para cada región delimitada por las cajas proporcionadas.
"""

import matplotlib.pyplot as plt
plot_binary_masks(cumulative_mask)

"""AHORA ESCOGES LA OPCION MAS ADECUADA"""

OPCION=2
plot_binary_mask2(cumulative_mask[OPCION-1], title='MASCARA ELEGIDA')

OPCION2=2

"""---

### SOLO VALIDO CUANDO SE VA A SEGMENTAR HOJAS ENFERMAS
"""

#SOLO PARA HOJAS ENFERMAS
plot_binary_masks(maskss[len(boxx)-OP])

"""---

---

### SOLO VALIDO CUANDO SE VA A SEGMENTAR HOJAS ENFERMAS
"""

#SOLO PARA HOJAS ENFERMAS
OPCION2=2
plot_binary_mask2(maskss[len(boxx)-OP][OPCION2-1], title='MASCARA ELEGIDA')

"""---

# A) ACTUALIZAR LISTAS DE MASCARAS DEACUERDO A LAS OPCIONES ELEGIDAS
"""

lista_de_mascaras=ACTUALIZAR_MASK(boxx, mask_predictor,  OP, OPCION, OPCION2)

"""# B)  CONVIERTE LAS MASKCARAS EN FORMATO .JSON"""

# para quitar grafica ver=False
estructura_deseada = convertir_JSON(boxx, IMAGE_PATH, widget, lista_de_mascaras, CLASE, OP, ver=True)

"""## C) **GUARDA EL ARCHIVO EN FORMATO .JSON**"""

GUARDAR_JSON(estructura_deseada, IMAGE_PATH,rutaJson)

"""print('[Ir a mi sección](#mi_seccion)')

---

---

---
"""