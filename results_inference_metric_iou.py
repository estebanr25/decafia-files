# -*- coding: utf-8 -*-
"""RESULTS_INFERENCE_METRIC_IOU.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FrncbU5Dk6Yrq9s4N6yDscINZG6gsqtX

# Mirar targeta grafica
"""



!nvidia-smi

"""function ClickConnect() {
var iconElement = document-getElementById("toggle-header-button");
if (iconElement) {
var clickEvent - new MouseEvent ("click", {
bubbles: true, cancelable: true,
view: window
½);
iconElement.dispatchEvent (clickEvent);
}
}
setInterval(ClickConnect,
6000);

# **VERIFICAR ENTORNO**
"""

import cython; import h5py; import imgaug; import ipython_genutils; import keras; import matplotlib
import numpy; import cv2; import skimage; import scipy; import tensorboard; import tensorflow
print("Versión de Cython:", cython.__version__); print("Versión de h5py:", h5py.__version__); print("Versión de imgaug:", imgaug.__version__)
print("Versión de ipython-genutils:", ipython_genutils.__version__); print("Versión de Keras:", keras.__version__); print("Versión de Matplotlib:", matplotlib.__version__)
print("Versión de NumPy:", numpy.__version__); print("Versión de OpenCV (opencv-contrib-python):", cv2.__version__); print("Versión de scikit-image:", skimage.__version__)
print("Versión de SciPy:", scipy.__version__); print("Versión de TensorBoard:", tensorboard.__version__); print("Versión de TensorFlow:", tensorflow.__version__)

"""# **CARGAR LIBRERIAS**"""

import os
import sys
import json
import numpy as np
import time
from PIL import Image, ImageDraw
import skimage.draw
import random
from google.colab import drive
# Montar Google Drive
drive.mount('/content/drive')

"""# **CLONAR REPOSITORIO GITHUB**"""

# Clone the repo
!git clone https://github.com/andryshalom/DECAFIA-MASK_RCNN_TF2_14_EDIT.git maskrcnn
# Change the runtime directory to the cloned repo
import os
os.chdir('/content/maskrcnn/')
# Download pre-trained weights
#!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5

"""## **MUY IMPORTANTE**"""

ROOT_DIR = '/content/maskrcnn'
assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist'

sys.path.append(ROOT_DIR)

from mrcnn import visualize
from mrcnn.config import Config
from mrcnn import model as modellib, utils
# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, "logs")

"""#CONFIG 2"""

class CustomConfig(Config):
    """Configuration for training on the helmet  dataset.
    """
    # Give the configuration a recognizable name
    NAME = "object"

    # Número de imágenes a entrenar en cada GPU. Una GPU de 12 GB puede manejar típicamente
    # 2 imágenes de 1024x1024 px.
    # Ajusta según la memoria de tu GPU y el tamaño de las imágenes. Utiliza el número más alto
    # que tu GPU pueda manejar para un mejor rendimiento
    # BATCH_SIZE=IMAGES_PER_GPU * GPU_COUNT
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

    # Number of classes (including background)
    NUM_CLASSES = 1 + 4  # background + objetos

    # All of our training images are 960x960
    IMAGE_MIN_DIM = 192
    IMAGE_MAX_DIM = 960

    # BATCH_SIZE=1    # tamaño del BACH (division del conjunto de datos train)
    # BATCH_SIZE=IMAGES_PER_GPU * GPU_COUNT
    # STEPS_PER_EPOCH = num_de_imagenes_train/batch_size (se recorre almenos una vez cada imagen redondeo hacia la derecha)
    # STEPS_PER_EPOCH = 813/BATCH_SIZE
    # Número de pasos de entrenamiento por época.
    # Esto no necesita coincidir con el tamaño del conjunto de entrenamiento. Los registros de Tensorboard
    # se guardan al final de cada época, por lo que establecer esto en un número
    # más pequeño significa obtener actualizaciones más frecuentes de TensorBoard.
    # Las estadísticas de validación también se calculan al final de cada época y pueden llevar un tiempo,
    # así que no lo establezcas muy pequeño para evitar pasar mucho tiempo en estadísticas de validación.
    STEPS_PER_EPOCH = 1934 #1934



    # Número de pasos de validación que se ejecutarán al final de cada época de entrenamiento.
    # Un número mayor mejora la precisión de las estadísticas de validación, pero ralentiza el entrenamiento.
    # no hacer mas de 10
    VALIDATION_STEPS = 20

    # Arquitectura de la red "backbone".
    # Los valores soportados son: resnet50, resnet101.
    # También puedes proporcionar una función que debe tener la firma
    # de model.resnet_graph. Si lo haces, también necesitas proporcionar una función
    # a COMPUTE_BACKBONE_SHAPE.

    BACKBONE = 'resnet101' #'resnet50'

    # Media RGB para nuestra base de datos: [ 91.78358868 129.7007309  112.42858215]
    MEAN_PIXEL = np.array([82.8, 124.3, 99.7]) # Media RGB: [ 82.7938383  124.32991352  99.68951586]

    # imagenes de 640x640  (Escalas de Anclaje para la RPN):
    # es recomendable ajustar las escalas de anclaje (RPN_ANCHOR_SCALES) para abarcar adecuadamente este rango de tamaños
    # La elección de las escalas de anclaje puede depender de las características específicas de tu conjunto de datos.
    # Experimenta con diferentes configuraciones y observa cómo afectan la detección de objetos en tu escenario particular.
    # Longitud del lado de la ancla cuadrada en píxeles
    RPN_ANCHOR_SCALES = (24,  38,  80, 480, 880)  # [ 19.  37. 114. 395. 789.] #(16,  32,  64, 176, 365, 602, 860)   # #[ 19.  37. 114. 408. 777.](17, 33, 101, 408, 771)   #(27, 75, 192, 450, 810) #(18, 50, 128, 300, 540)*1.5
    #(18, 50, 128, 300, 540) para la base de datos de 640 pero como se aumento un 50% se multiplica 1.5
    RPN_ANCHOR_RATIOS = [0.75, 1.0, 2.25]
    # The strides of each layer of the FPN Pyramid. These values
    # are based on a Resnet101 backbone.
    BACKBONE_STRIDES = [4, 8, 16, 32, 64]#   [2, 4, 8, 16, 32, 64, 128]
    # Tasa de aprendizaje y momentum
    # El documento Mask RCNN utiliza lr=0.02, pero en TensorFlow provoca
    # que los pesos exploten. Probablemente debido a diferencias en la implementación del optimizador.
    LEARNING_RATE = 0.001
    LEARNING_MOMENTUM = 0.9
    # Regularización de peso
    #prevenir el sobreajuste (overfitting) y mejorar la generalización del modelo.
    #La idea básica detrás de la regularización de peso es
    # penalizar los pesos grandes en la función de pérdida durante el entrenamiento.
    WEIGHT_DECAY = 0.0001#0.0001
    # Umbral de supresión no máxima para filtrar propuestas RPN.
    # Puedes aumentar esto durante el entrenamiento para generar más propuestas.
    RPN_NMS_THRESHOLD = 0.75
    # Valor de probabilidad mínimo para aceptar una instancia detectada
    # ROIs por debajo de este umbral se omiten
    DETECTION_MIN_CONFIDENCE = 0.79
    # Umbral de supresión no máxima para detección
    DETECTION_NMS_THRESHOLD = 0.3
    # Si está habilitado, redimensiona las máscaras de instancia a un tamaño más pequeño para reducir
    # la carga de memoria. Recomendado cuando se usan imágenes de alta resolución.
    USE_MINI_MASK = False
    MINI_MASK_SHAPE = (60, 60)  # (altura, ancho) de la mini-máscara
    # Número de ROIs por imagen para alimentar a las cabezas clasificadoras/máscara
    # El documento Mask RCNN utiliza 512, pero a menudo el RPN no genera
    # suficientes propuestas positivas para llenar esto y mantener una relación positiva:negativa
    # de 1:3. Puedes aumentar el número de propuestas ajustando
    # el umbral de RPN NMS.

    # Especifica el número de Regiones de Interés (ROIs) que se seleccionan para el entrenamiento de cada imagen.
    # Las ROIs son regiones propuestas que se utilizan para entrenar la red en la tarea de clasificación
    # y regresión de cajas delimitadoras.
    TRAIN_ROIS_PER_IMAGE = 200
    #Limita el número máximo de instancias (objetos) anotadas que se utilizarán durante el entrenamiento.
    # Si tienes un conjunto de datos con un gran número de instancias, este parámetro puede ayudar a controlar
    # la cantidad de datos utilizados durante cada iteración de entrenamiento.
    MAX_GT_INSTANCES = 78

    # (ROIs después de la supresión no máxima - Inferencia):
    #bEspecifica el número de ROIs que se conservarán después de aplicar la supresión no máxima durante la inferencia.
    # Después de la predicción de la RPN, se utilizan técnicas de supresión no máxima para reducir el número de
    # propuestas redundantes.
    POST_NMS_ROIS_INFERENCE = 2000

    #(ROIs después de la supresión no máxima - Entrenamiento):
    # Similar a POST_NMS_ROIS_INFERENCE, pero aplicado durante el entrenamiento. Después de la predicción de la RPN
    # y antes de pasar a las etapas subsiguientes del modelo, se aplica la supresión no máxima para limitar
    # el número de ROIs utilizadas durante el entrenamiento.
    POST_NMS_ROIS_TRAINING = 1000
    #
    # Número máximo de detecciones finales
    DETECTION_MAX_INSTANCES = 78
    # Porcentaje de ROIs positivas utilizadas para entrenar cabezas clasificadoras/máscara
    ROI_POSITIVE_RATIO = 0.3
    # Esto significa que los parámetros de escala y desplazamiento de la BN se optimizarán
    # junto con los demás parámetros de la red durante el entrenamiento.
    TRAIN_BN = True
    # Pesos de pérdida para una optimización más precisa.
    # Pueden usarse para la configuración de entrenamiento R-CNN.
    # controla el peso de la insidencia de una funcion de costo especifica
    LOSS_WEIGHTS = {
        "rpn_class_loss": 1.,
        "rpn_bbox_loss": 1.,
        "mrcnn_class_loss": 1.,
        "mrcnn_bbox_loss": 1.,
        "mrcnn_mask_loss": 1.
    }
config = CustomConfig()
config.display()

"""# COMBINAR CARPETAS SEPARADAS"""

!pip install rarfile

import rarfile
import json
import os

def descomprimir_rar(ruta_rar):
    # Crear una instancia de la clase RarFile
    with rarfile.RarFile(ruta_rar) as rf:
        # Extraer todos los archivos en la misma carpeta que el .rar
        rf.extractall(os.path.dirname(ruta_rar))

import shutil

# Definir las rutas de las carpetas originales
rutas_multiples = ["/content/maskrcnn/images/train4", "/content/maskrcnn/images/train4b","/content/maskrcnn/images/train4c"]

# Definir la ruta de la nueva carpeta
ruta_nueva = "/content/maskrcnn/images/train_merged"

# Crear la carpeta nueva si no existe
if not os.path.exists(ruta_nueva):
    os.makedirs(ruta_nueva)

# Mover el contenido de las carpetas originales a la carpeta nueva
for ruta in rutas_multiples:
    # Obtener la lista de archivos en la carpeta original
    archivos = os.listdir(ruta)
    # Mover cada archivo a la carpeta nueva
    for archivo in archivos:
        shutil.move(os.path.join(ruta, archivo), ruta_nueva)

print("¡Contenido de las carpetas movido exitosamente a la nueva carpeta!")

# Ruta del archivo .rar en Google Drive
ruta_rar = "/content/maskrcnn/images/val4/via_region_data.rar"
# Descomprimir el archivo .rar
descomprimir_rar(ruta_rar)
# Ruta del archivo .rar en Google Drive
ruta_rar = "/content/maskrcnn/images/train_merged/via_region_data.rar"
# Descomprimir el archivo .rar
descomprimir_rar(ruta_rar)

"""# CUSTOMDATASET"""

class CustomDataset(utils.Dataset):

    def load_custom(self, dataset_dir, subset):
        """Load a subset of the bottle dataset.
        dataset_dir: Root directory of the dataset.
        subset: Subset to load: train or val
        """
        # Add classes. We have only one class to add.
        self.add_class("object", 1, "HOJAS")
        self.add_class("object", 2, "ROYA")
        self.add_class("object", 3, "COCO")
        self.add_class("object", 4, "MINADOR")
        #self.add_class("object", 5, "SANAS")

        # Train or validation dataset?
        assert subset in ["train_merged", "val4","test4"] #["TRAIN960", "VAL960"]
        dataset_dir = os.path.join(dataset_dir, subset)
        #for dataset_dir in dataset_dirs:
        #    dataset_dir = os.path.join(dataset_dir, subset)
            #annotations.extend(self.load_annotations(dataset_dir))

        # Load annotations
        # VGG Image Annotator saves each image in the form:
        # { 'filename': '28503151_5b5b7ec140_b.jpg',
        #   'regions': {
        #       '0': {
        #           'region_attributes': {},
        #           'shape_attributes': {
        #               'all_points_x': [...],
        #               'all_points_y': [...],
        #               'name': 'polygon'}},
        #       ... more regions ...
        #   },
        #   'size': 100202
        # }
        # We mostly care about the x and y coordinates of each region
        annotations1 = json.load(open(os.path.join(dataset_dir, "via_region_data.json"))) ## se puede cambiar el nombre
        # print(annotations1)
        annotations = list(annotations1.values())  # don't need the dict keys

        # The VIA tool saves images in the JSON even if they don't have any
        # annotations. Skip unannotated images.
        annotations = [a for a in annotations if a['regions']]

        # Add images
        for a in annotations:
            # print(a)
            # Get the x, y coordinaets of points of the polygons that make up
            # the outline of each object instance. There are stores in the
            # shape_attributes (see json format above)
            #a=dict(a)

            #polygons = [r['shape_attributes'] for r in a['regions'].values()]
            #objects = [s['region_attributes'].get('objetos', 'ENFERMAS') for s in a['regions'].values()] #['objetos']
            #objects = [s['region_attributes']['objetos'] for s in a['regions'].values()]
            if isinstance(a['regions'], list):
                polygons = [r['shape_attributes'] for r in a['regions']]
                objects = [s['region_attributes']['objetos'] for s in a['regions']]
            elif isinstance(a['regions'], dict):
                polygons = [r['shape_attributes'] for r in a['regions'].values()]
                objects = [s['region_attributes']['objetos'] for s in a['regions'].values()]
            else:
                # Manejar otros casos si es necesario
                print("a['regions'] no es ni una lista ni un diccionario conocido")

            name_dict = {"HOJAS": 1,"ROYA": 2,"COCO": 3,"MINADOR": 4}  #{"ENFERMAS": 1,"ROYA": 2,"COCO": 3,"MINADOR": 4,"SANAS": 5}
            num_ids = [name_dict[a] for a in objects]
            # load_mask() needs the image size to convert polygons to masks.
            # Unfortunately, VIA doesn't include it in JSON, so we must read
            # the image. This is only managable since the dataset is tiny.
            #print("numids",num_ids)
            nombree=os.path.splitext(os.path.basename(a['filename']))[0]+".jpg"#f"{os.path.basename(a['filename'])}.jpg"
            image_path = os.path.join(dataset_dir, nombree)
            image = skimage.io.imread(image_path)
            height, width = image.shape[:2]

            self.add_image(
                "object",  ## for a single class just add the name here
                image_id=nombree,  # a['filename']use file name as a unique image id
                path=image_path,
                width=width, height=height,
                polygons=polygons,
                num_ids=num_ids)

    def load_mask(self, image_id):
        """Generate instance masks for an image.
        Returns:
        masks: A bool array of shape [height, width, instance count] with
            one mask per instance.
        class_ids: a 1D array of class IDs of the instance masks.
        """
        # If not a bottle dataset image, delegate to parent class.
        image_info = self.image_info[image_id]
        if image_info["source"] != "object":
            return super(self.__class__, self).load_mask(image_id)

        # Convert polygons to a bitmap mask of shape
        # [height, width, instance_count]
        info = self.image_info[image_id]
        if info["source"] != "object":
            return super(self.__class__, self).load_mask(image_id)
        num_ids = info['num_ids']
        mask = np.zeros([info["height"], info["width"], len(info["polygons"])],
                        dtype=np.uint8)
        bounding_boxes = []  # Initialize bounding_boxes as an empty list
        for i, p in enumerate(info["polygons"]):
            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])
            rr = np.clip(rr, 0, info["height"] - 1)
            cc = np.clip(cc, 0, info["width"] - 1)
            mask[rr, cc, i] = 1

            # Find bounding box coordinates
            y_min, y_max = np.min(rr), np.max(rr)
            x_min, x_max = np.min(cc), np.max(cc)
            bounding_boxes.append([y_min, x_min, y_max, x_max])

        bounding_boxes = np.asarray(bounding_boxes)
        num_ids = np.array(num_ids, dtype=np.int32)

        return mask, num_ids, bounding_boxes


    def image_reference(self, image_id):
        """Return the path of the image."""
        info = self.image_info[image_id]
        if info["source"] == "object":
            return info["path"]
        else:
            super(self.__class__, self).image_reference(image_id)

"""# CARGAR DATOS"""

# Crear una instancia del dataset
dataset_val = CustomDataset()

# Definir una sola ruta
ruta_unica = "/content/maskrcnn/images"
# Definir una lista de dos rutas
rutas_multiples = "/content/maskrcnn/images"

# Cargar datos desde una sola ruta
#dataset_val.load_custom(ruta_unica, "val4")
# O cargar datos desde dos rutas diferentes
dataset_val.load_custom(rutas_multiples, "train_merged")

# Preparar el dataset
dataset_val.prepare()

dataset_train = CustomDataset()
dataset_train.load_custom("/content/maskrcnn/images", "train_merged") #"TRAIN960"
dataset_train.prepare()

# Validation dataset
dataset_val = CustomDataset()
dataset_val.load_custom("/content/maskrcnn/images", "val4") #"VAL960"
dataset_val.prepare()

dataset_test = CustomDataset()
dataset_test.load_custom("/content/maskrcnn/images", "test4") #"TRAIN960"
dataset_test.prepare()

"""# **FUNCIONES VARIAS**"""

import matplotlib.pyplot as plt
import numpy as np
"""
Funciones para calcular la Intersección sobre Unión (IoU).

1. calculate_iou(gt_mask, pred_mask):
   - Calcula la IoU entre dos máscaras.

2. calculate_average_iou_for_clases(dataset, model):
   - Calcula el IoU promedio para cada clase en un conjunto de datos.

3. IoU_function(mask_real, mask_results, plot_results=True):
   - Calcula la IoU entre dos máscaras y opcionalmente muestra una visualización.

4. calculate_iou2(gt_mask, pred_mask, class_name, image_id, plot_results=True):
   - Calcula la IoU entre dos máscaras con opciones para mostrar visualizaciones.
"""

def calculate_iou(gt_mask, pred_mask):
    intersection = np.logical_and(gt_mask, pred_mask)
    union = np.logical_or(gt_mask, pred_mask)
    iou = np.sum(intersection) / np.sum(union)
    return iou

def calculate_average_iou_for_clases(dataset, model):
    class_names = ['BG', 'HOJAS', 'ROYA', 'COCO', 'MINADOR']
    IoU_list = {class_name: [] for class_name in class_names}

    try:

        for image_id in dataset.image_ids:
            image = dataset.load_image(image_id)
            gt_masks, gt_class_ids,_ = dataset.load_mask(image_id)

            results = model.detect([image], verbose=1)
            r = results[0]

            for class_id in np.unique(np.concatenate([gt_class_ids, r['class_ids']])):
                gt_class_mask = np.sum(gt_masks[:, :, gt_class_ids == class_id], axis=-1, keepdims=True)
                pred_class_mask = np.sum(r['masks'][:, :, r['class_ids'] == class_id], axis=-1, keepdims=True)

                IoU = calculate_iou(gt_class_mask, pred_class_mask)
                IoU_list[class_names[class_id]].append(IoU)

                print(f'Image {image_id}, Class {class_names[class_id]} IoU: {IoU}')
        # Calculate and print the average IoU for each class
        average_iou_dict = {}
        for class_name in class_names:
            average_iou = np.mean(IoU_list[class_name])
            average_iou_dict[class_name] = average_iou
            print(f'Average IoU for {class_name}: {average_iou}')

    except KeyboardInterrupt:
        print("Función interrumpida")
        return IoU_list  # Puedes cambiar esto por el valor que desees cuando se interrumpe

    return IoU_list


def IoU_function(mask_real, mask_results,plot_results=True):

    annotation_mask = np.zeros((mask_real.shape[0], mask.shape[1]))
    for i in range(mask_real.shape[2]):
        annotation_mask = np.logical_or(annotation_mask, mask_real[:,:,i])
        #plt.imshow(annotation_mask,cmap='binary')
        #plt.show()

    result_mask = np.zeros((mask_results.shape[0], mask_results.shape[1]))
    for i in range(r['masks'].shape[2]):
        result_mask = np.logical_or(result_mask, mask_results[:,:,i])
        #plt.imshow(result_mask, cmap='binary')
        #plt.show()

    intersection = np.logical_and(annotation_mask, result_mask)
    union = np.logical_or(annotation_mask, result_mask)

    IoU = np.sum(intersection) / np.sum(union)

    if(plot_results):
        colors = visualize.random_colors(2)
        IoU_image = visualize.apply_mask(image, intersection,(1.0, 0.0, 0.0), alpha=0.8)
        IoU_image = visualize.apply_mask(IoU_image, union, (0.0, 1.0, 0.0), alpha=0.3)
        plt.figure(figsize = (10,10))
        plt.text(20, 30, 'Union',bbox=dict(facecolor='green', alpha=0.5))
        plt.text(20, 50, 'Intersection',bbox=dict(facecolor='red', alpha=0.5))
        plt.title('IoU Image - Intersection over Union')
        plt.imshow(IoU_image)
        plt.show()

    return IoU;

def calculate_iou2(gt_mask, pred_mask, class_name, image_id, plot_results=True):
    # Ensure both masks have the same shape
    if gt_mask.shape != pred_mask.shape:
        pred_mask = resize(pred_mask, gt_mask.shape, mode='constant', preserve_range=True)

    intersection = np.logical_and(gt_mask, pred_mask)
    union = np.logical_or(gt_mask, pred_mask)
    iou = np.sum(intersection) / np.sum(union)

    if plot_results:
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.imshow(gt_mask, cmap='binary')
        plt.title(f'Ground Truth {class_name}')
        plt.subplot(1, 2, 2)
        plt.imshow(pred_mask, cmap='binary')
        plt.title(f'Predicted {class_name}')
        plt.show()

    return iou


def IOU_class_comparador(dataset, model, plot_results=True):
    class_names = ['BG', 'HOJAS', 'ROYA', 'COCO','MINADOR']
    IoU_list = {class_name: [] for class_name in class_names}


    for image_id in dataset.image_ids:
        image = dataset.load_image(image_id)
        gt_masks, gt_class_ids = dataset.load_mask(image_id)

        results = model.detect([image], verbose=1)
        r = results[0]

        for class_id in np.unique(np.concatenate([gt_class_ids, r['class_ids']])):
            gt_class_mask = np.sum(gt_masks[:, :, gt_class_ids == class_id], axis=-1, keepdims=True)
            pred_class_mask = np.sum(r['masks'][:, :, r['class_ids'] == class_id], axis=-1, keepdims=True)

            IoU = calculate_iou2(gt_class_mask, pred_class_mask, class_names[class_id], image, plot_results)
            IoU_list[class_names[class_id]].append(IoU)

            print(f'Image {image_id}, Class {class_names[class_id]} IoU: {IoU}')

    # Calculate and print the average IoU for each class
    for class_name in class_names:
        average_iou = np.mean(IoU_list[class_name])
        print(f'Average IoU for {class_name}: {average_iou}')

"""# MOSTRAR DATOS"""

# Load and display random samples
dataset = dataset_train
image_ids = np.random.choice(dataset.image_ids, 4)
for image_id in image_ids:
    print(image_id)
    image = dataset.load_image(image_id)
    mask, class_ids, boxxes = dataset.load_mask(image_id)
    print(dataset.image_reference(image_id))
    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)

from mrcnn.model import log
# Load random image and mask.
image_id = random.choice(dataset.image_ids)
image = dataset.load_image(image_id)
mask, class_ids, boxxes = dataset.load_mask(image_id)
# Compute Bounding box
bbox = utils.extract_bboxes(mask)

# Display image and additional stats
print("image_id ", image_id, dataset.image_reference(image_id))
log("image", image)
log("mask", mask)
log("class_ids", class_ids)
log("bbox", bbox)
# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)

"""# **CONFIGURACION DEL MODO DE INFERENCIA DEL MODELO**"""

class InferenceConfig(CustomConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    DETECTION_MIN_CONFIDENCE = 0.95
inference_config = InferenceConfig()

# Recreate the model in inference mode
model = modellib.MaskRCNN(mode="inference", config=inference_config,  model_dir=MODEL_DIR)

"""# **CARGAR PESOS DEL MODELO GUARDADO EN GOOGLE DRIVE**"""

import gdown
enlace_compartido = "https://drive.google.com/file/d/1-28oIWRI9NWVEOxUeTyhQnTFmclrNrgf/view?usp=drive_link"
#https://drive.google.com/file/d/1-28oIWRI9NWVEOxUeTyhQnTFmclrNrgf/view?usp=drive_link
# Extraer el ID del archivo
id_del_archivo = enlace_compartido.split("/")[-2]
id_del_archivo = id_del_archivo.split("?")[0]  # Eliminar cualquier parámetro adicional en la URL
# Construir la URL de descarga
model_url = f'https://drive.google.com/uc?id={id_del_archivo}'
# Descargar el modelo
model_path= 'modelo_inferencia.h5'
gdown.download(model_url, model_path, quiet=False)
# Load trained weights (fill in path to trained weights here)
assert model_path != "", "Provide path to trained weights"
print("Loading weights from ", model_path)
model.load_weights(model_path, by_name=True)

"""# FILTRO PARA ILUMINACION EXCESIVA DE LUZ"""

import cv2
import numpy as np
import os  # Agregar esta línea para importar el módulo os
from shapely.geometry import Polygon , Point
def filtrar_y_reemplazar_blanco2(imagen):
    # Convertir la imagen a escala de grises
    gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
    # Ajustar el umbral para separar los píxeles blancos del fondo
    _, umbral = cv2.threshold(gris, 190, 255, cv2.THRESH_BINARY)
    # Encontrar contornos en la imagen
    contours, _ = cv2.findContours(umbral, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # Verificar si se detectaron contornos
    if contours:
        # Encontrar el contorno principal (el más grande)
        contorno_principal = max(contours, key=cv2.contourArea)
        # Calcular el rectángulo delimitador para el contorno principal
        x, y, w, h = cv2.boundingRect(contorno_principal)
        # Extraer la región de interés (ROI) de la imagen
        roi = imagen[y:y+h, x:x+w]
        # Calcular el polígono original
        poligono_original = Polygon(contorno_principal[:, 0, :])
        # Calcular el polígono contenedor alrededor del contorno principal con un margen de 2 píxeles
        contenedor = poligono_original.buffer(2)
        # Calcular el valor promedio de color de la región del contorno principal
        promedio_color_contorno = np.mean([roi[int(punto[0][1] - y), int(punto[0][0] - x)] for punto in contorno_principal], axis=0).astype(np.uint8)
        # Crear una máscara de la región blanca
        mascara = cv2.bitwise_not(umbral)
        # Crear una imagen completamente gris del mismo tamaño que la original
        gris = np.full_like(imagen, promedio_color_contorno, dtype=np.uint8)
        # Combinar la imagen original con el color promedio utilizando la máscara
        imagen_reemplazada = np.where(mascara[..., None], imagen, gris)
    else:
        # Si no se detectaron contornos, devolver la imagen original sin ningún procesamiento
        imagen_reemplazada = imagen
    return imagen_reemplazada

"""# **PRUEBA DE MASCARAS DEL MODELO (BETA)**"""

import skimage
import matplotlib.pyplot as plt

# CLASES= ['BG', 'HOJAS', 'ROYA', 'COCO', 'MINADOR']

real_test_dir = '/content/drive/MyDrive/fotos_inferencia'#'/content/maskrcnn/images/val2/'
image_paths = []
for filename in os.listdir(real_test_dir):
    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:
        image_paths.append(os.path.join(real_test_dir, filename))

for image_path in image_paths:
    img = skimage.io.imread(image_path)

    if img.ndim != 3:
      image = skimage.color.gray2rgb(img)
    elif img.shape[-1] == 4:
      image = img[..., :3]
    else:
      image = img

    print(image_path)
    img_arr = np.array(image)
    results = model.detect([img_arr], verbose=1)
    r = results[0]
    visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'],
                                dataset_val.class_names, r['scores'], figsize=(5,5))
    # Ajusta el tamaño de las etiquetas de clase después de la visualización
for class_id, score, bbox in zip(r['class_ids'], r['scores'], r['rois']):
    y1, x1, y2, x2 = bbox
    label = dataset_val.class_names[class_id]
    plt.annotate(f"{label} {score:.2f}", (x1, y1), color='white', backgroundcolor='red', fontsize=8)

# Muestra la imagen con las etiquetas de clase ajustadas
plt.show()

import skimage
import matplotlib.pyplot as plt
conteo=0
conteo2=0
# CLASES= ['BG', 'HOJAS', 'ROYA', 'COCO', 'MINADOR']

real_test_dir = '/content/drive/MyDrive/fotos_inferencia'#'/content/maskrcnn/images/val2/'
image_paths = []
for filename in os.listdir(real_test_dir):
    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:
        image_paths.append(os.path.join(real_test_dir, filename))

for image_path in image_paths:
    img = skimage.io.imread(image_path)

    if img.ndim != 3:
      image = skimage.color.gray2rgb(img)
    elif img.shape[-1] == 4:
      image = img[..., :3]
    else:
      image = img

    print(image_path)
    img_arr = np.array(image)
    results = model.detect([img_arr], verbose=1)
    r = results[0]
    # Encuentra la máscara correspondiente a la región más grande de la clase 1 (si existe)
    largest_mask_index = None
    largest_mask_area = 0
    for i in range(r['masks'].shape[2]):
        if r['class_ids'][i] == 1:  # Verifica si la clase es la clase 1
            mask_area = np.sum(r['masks'][:,:,i])
            if mask_area > largest_mask_area:
                largest_mask_area = mask_area
                largest_mask_index = i

    # Muestra solo la máscara correspondiente a la región más grande de la clase 1
    if largest_mask_index is not None:
        largest_mask = r['masks'][:,:,largest_mask_index]

        # Calcula el área de la región más grande de la clase 1
        area_largest_mask = np.sum(largest_mask)

        # Filtra las máscaras de las clases 2, 3 y 4
        acumulate_2 = np.zeros_like(largest_mask, dtype=np.uint8)  # Inicializa la máscara acumulada para clase 2
        acumulate_3 = np.zeros_like(largest_mask, dtype=np.uint8)  # Inicializa la máscara acumulada para clase 3
        acumulate_4 = np.zeros_like(largest_mask, dtype=np.uint8)  # Inicializa la máscara acumulada para clase 4
        for i in range(r['masks'].shape[2]):
            if r['class_ids'][i] == 2:  # Verifica si la clase es la clase 2
                acumulate_2 = np.where(r['masks'][:,:,i], 1, acumulate_2)  # Asigna valor 1 en la máscara acumulada de clase 2
            elif r['class_ids'][i] == 3:  # Verifica si la clase es la clase 3
                acumulate_3 = np.where(r['masks'][:,:,i], 1, acumulate_3)  # Asigna valor 1 en la máscara acumulada de clase 3
            elif r['class_ids'][i] == 4:  # Verifica si la clase es la clase 4
                acumulate_4 = np.where(r['masks'][:,:,i], 1, acumulate_4)  # Asigna valor 1 en la máscara acumulada de clase 4

        # Calcula la intersección entre la máscara más grande de la clase 1 y las máscaras filtradas
        acumulate_2 = np.logical_and(largest_mask, acumulate_2)
        # Calcula la intersección entre la máscara más grande de la clase 1 y las máscaras filtradas
        acumulate_3 = np.logical_and(largest_mask, acumulate_3)
        # Calcula la intersección entre la máscara más grande de la clase 1 y las máscaras filtradas
        acumulate_4 = np.logical_and(largest_mask, acumulate_4)


        # Superpone las máscaras acumuladas con colores diferentes
        overlay = np.zeros(largest_mask.shape + (3,), dtype=np.uint8)
        overlay[acumulate_2 == 1] = [255, 0, 0]  # Rojo para clase 2
        overlay[acumulate_3 == 1] = [0, 255, 0]  # Verde para clase 3
        overlay[acumulate_4 == 1] = [0, 0, 255]  # Azul para clase 4



        # Calcula el área de cada acumulación
        area_acumulate_2 = np.sum(acumulate_2)
        area_acumulate_3 = np.sum(acumulate_3)
        area_acumulate_4 = np.sum(acumulate_4)

        # Calcula la relación de área y expresa como porcentaje
        ratio_2 = (area_acumulate_2 / area_largest_mask) * 100
        ratio_3 = (area_acumulate_3 / area_largest_mask) * 100
        ratio_4 = (area_acumulate_4 / area_largest_mask) * 100

        # Imprime los resultados
        print(f"Relación de área para clase 2: {ratio_2:.2f}%")
        print(f"Relación de área para clase 3: {ratio_3:.2f}%")
        print(f"Relación de área para clase 4: {ratio_4:.2f}%")

        conteo2 += 1


        # Muestra la imagen superpuesta
        plt.imshow(largest_mask, cmap='gray')
        plt.imshow(overlay, alpha=0.5)  # Superpone las máscaras acumuladas con transparencia
        plt.title('Superposición de máscaras acumuladas')
        plt.axis('off')
        plt.show()
    else:
        print("No se encontró ninguna región de la clase 1.")
        conteo += 1

"""# PRUEBAS DE DETECCION"""

import skimage
import matplotlib.pyplot as plt

real_test_dir = '/content/drive/MyDrive/fotos_inferencia'
image_paths = []
for filename in os.listdir(real_test_dir):
    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:
        image_paths.append(os.path.join(real_test_dir, filename))

for image_path in image_paths:
    img = skimage.io.imread(image_path)
    #img = filtrar_y_reemplazar_blanco2(img)

    if img.ndim != 3:
        image = skimage.color.gray2rgb(img)
    elif img.shape[-1] == 4:
        image = img[..., :3]
    else:
        image = img

    print(image_path)
    img_arr = np.array(image)
    results = model.detect([img_arr], verbose=1)
    r = results[0]

    fig, ax = plt.subplots(figsize=(8, 6))
    ax.imshow(image)

    # Diccionario para asignar un color único a cada clase
    color_dict = {
        1: 'red',
        2: 'green',
        3: 'blue',
        4: 'orange',  # Añade más colores según sea necesario
        # Agrega más clases y colores según sea necesario
    }

    # Mostrar cuadros delimitadores y etiquetas de todas las clases detectadas
    for class_id, score, bbox in zip(r['class_ids'], r['scores'], r['rois']):
        if class_id in color_dict:  # Verifica si la clase tiene un color asignado
            y1, x1, y2, x2 = bbox
            label = dataset_val.class_names[class_id]
            color = color_dict[class_id]
            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor=color, linewidth=2))
            ax.text(x1, y1, f"{label} {score:.2f}", color='white', fontsize=8, bbox=dict(facecolor=color, alpha=0.5))

    plt.axis('off')
    plt.show()

"""# Prueba superposicion"""

import matplotlib.pyplot as plt
import numpy as np

# Encuentra la máscara correspondiente a la región más grande de la clase 1 (si existe)
largest_mask_index = None
largest_mask_area = 0
for i in range(r['masks'].shape[2]):
    if r['class_ids'][i] == 1:  # Verifica si la clase es la clase 1
        mask_area = np.sum(r['masks'][:,:,i])
        if mask_area > largest_mask_area:
            largest_mask_area = mask_area
            largest_mask_index = i

# Muestra solo la máscara correspondiente a la región más grande de la clase 1
if largest_mask_index is not None:
    largest_mask = r['masks'][:,:,largest_mask_index]

    # Calcula el área de la región más grande de la clase 1
    area_largest_mask = np.sum(largest_mask)

    # Filtra las máscaras de las clases 2, 3 y 4
    acumulate_2 = np.zeros_like(largest_mask, dtype=np.uint8)  # Inicializa la máscara acumulada para clase 2
    acumulate_3 = np.zeros_like(largest_mask, dtype=np.uint8)  # Inicializa la máscara acumulada para clase 3
    acumulate_4 = np.zeros_like(largest_mask, dtype=np.uint8)  # Inicializa la máscara acumulada para clase 4
    for i in range(r['masks'].shape[2]):
        if r['class_ids'][i] == 2:  # Verifica si la clase es la clase 2
            acumulate_2 = np.where(r['masks'][:,:,i], 1, acumulate_2)  # Asigna valor 1 en la máscara acumulada de clase 2
        elif r['class_ids'][i] == 3:  # Verifica si la clase es la clase 3
            acumulate_3 = np.where(r['masks'][:,:,i], 1, acumulate_3)  # Asigna valor 1 en la máscara acumulada de clase 3
        elif r['class_ids'][i] == 4:  # Verifica si la clase es la clase 4
            acumulate_4 = np.where(r['masks'][:,:,i], 1, acumulate_4)  # Asigna valor 1 en la máscara acumulada de clase 4

    # Superpone las máscaras acumuladas con colores diferentes
    overlay = np.zeros(largest_mask.shape + (3,), dtype=np.uint8)
    overlay[acumulate_2 == 1] = [255, 0, 0]  # Rojo para clase 2
    overlay[acumulate_3 == 1] = [0, 255, 0]  # Verde para clase 3
    overlay[acumulate_4 == 1] = [0, 0, 255]  # Azul para clase 4

    # Calcula el área de cada acumulación
    area_acumulate_2 = np.sum(acumulate_2)
    area_acumulate_3 = np.sum(acumulate_3)
    area_acumulate_4 = np.sum(acumulate_4)

    # Calcula la relación de área y expresa como porcentaje
    ratio_2 = (area_acumulate_2 / area_largest_mask) * 100
    ratio_3 = (area_acumulate_3 / area_largest_mask) * 100
    ratio_4 = (area_acumulate_4 / area_largest_mask) * 100

    # Imprime los resultados
    print(f"Relación de área para clase 2: {ratio_2:.2f}%")
    print(f"Relación de área para clase 3: {ratio_3:.2f}%")
    print(f"Relación de área para clase 4: {ratio_4:.2f}%")


    # Muestra la imagen superpuesta
    plt.imshow(largest_mask, cmap='gray')
    plt.imshow(overlay, alpha=0.5)  # Superpone las máscaras acumuladas con transparencia
    plt.title('Superposición de máscaras acumuladas')
    plt.axis('off')
    plt.show()
else:
    print("No se encontró ninguna región de la clase 1.")

"""# observando las rois

"""

import skimage
import matplotlib.pyplot as plt
import matplotlib.patches as patches

real_test_dir = '/content/maskrcnn/images/val2/'
image_paths = []
for filename in os.listdir(real_test_dir):
    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:
        image_paths.append(os.path.join(real_test_dir, filename))

for image_path in image_paths:
    img = skimage.io.imread(image_path)

    if img.ndim != 3:
      image = skimage.color.gray2rgb(img)
    elif img.shape[-1] == 4:
      image = img[..., :3]
    else:
      image = img
    print(image_path)
    img_arr = np.array(image)
    results = model.detect([img_arr], verbose=1)
    r = results[0]
    # Visualizar la imagen original
    plt.figure(figsize=(10, 10))
    plt.imshow(img_arr)

    # Iterar sobre todas las propuestas y dibujar rectángulos alrededor de ellas
    for class_id, score, bbox in zip(r['class_ids'], r['scores'], r['rois']):
        y1, x1, y2, x2 = bbox
        height = y2 - y1
        width = x2 - x1
        rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')
        label = dataset_val.class_names[class_id]
        plt.annotate(f"{label} {score:.2f}", (x1, y1), color='red', backgroundcolor='none', fontsize=6)
        plt.gca().add_patch(rect)

    plt.show()

"""# IoU ENTRENAMIENTO "GENERAL"
"""

import matplotlib.pyplot as plt
class_names = ['BG', 'HOJAS', 'ROYA', 'COCO','MINADOR']
IoU_list = []
try:
    for image_id in dataset_train.image_ids:
        image = dataset_train.load_image(image_id)
        mask, class_ids, boxxes = dataset_train.load_mask(image_id)
        #visualize.display_top_masks(image, mask, class_ids, dataset.class_names)
        results = model.detect([image], verbose=1)
        r = results[0]
        #visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'], figsize=(2,2))
        IoU = IoU_function(mask, r['masks'],plot_results=False)
        IoU_list.append(IoU)
        print('IoU:',IoU)
except KeyboardInterrupt as e:
        print(f"Función interrumpida. Mensaje de error: {e}")

print('Number of Evaluations:', len(IoU_list)); print('Average IoU: ',np.mean(IoU_list)); print('Standard Deviacion: ', np.std(IoU_list))
plt.hist(IoU_list)
plt.show()
plt.boxplot(IoU_list)
plt.show()

"""# **IOU ENTRENAMIENTO "POR CLASES"**"""

# Example usage:
IoU_list= calculate_average_iou_for_clases(dataset_test, model)

"""**HISTOGRAMA IoU**"""

class_names= ['BG', 'HOJAS', 'ROYA', 'COCO', 'MINADOR']
clss=4
# Obtener la lista de IoU para la clase específica
IoU_clase = IoU_list[class_names[clss]]

# Filtrar los valores por encima de 0.1
IoU_filtrado = [x for x in IoU_clase if x > 0]

# Imprimir estadísticas
print('Number of Evaluations for Class {}: {}'.format(class_names[clss], len(IoU_filtrado)))
print('Average IoU for Class {}: {:.4f}'.format(class_names[clss], np.mean(IoU_filtrado)))
print('Standard Deviation for Class {}: {:.4f}'.format(class_names[clss], np.std(IoU_filtrado)))

# Graficar el histograma y el boxplot actualizado
plt.hist(IoU_filtrado)
plt.title('IoU Histogram for Class {} (Filtered)'.format(class_names[clss]))
plt.show()
plt.boxplot(IoU_filtrado)
plt.title('IoU Boxplot for Class {} (Filtered)'.format(class_names[clss]))
plt.show()

"""GUARDAR INFORMACION IoU EN ARCHIVO .JSON"""

import json

# Ruta del archivo JSON
ruta_del_archivo_json = '/content/drive/My Drive/IoU_data_test.json'  # Reemplaza con la ruta deseada en tu Google Drive

# Estructura deseada a guardar en el archivo JSON
estructura_deseada = {
    'IoU_list': IoU_list,
    'class_names': class_names
}

# Guardar la estructura deseada en el archivo JSON
with open(ruta_del_archivo_json, 'w') as archivo_json:
    json.dump(estructura_deseada, archivo_json, separators=(',', ':'), indent=0)

print('Archivo guardado en:', ruta_del_archivo_json)

"""**EXTRAER ARCHIVOS IOU .JSON**"""

import json

# Ruta del archivo JSON
ruta_del_archivo_json = '/content/drive/My Drive/IoU_data.json'  # Ruta donde se encuentra tu archivo JSON

# Leer el contenido del archivo JSON
with open(ruta_del_archivo_json, 'r') as archivo_json:
    datos_json = json.load(archivo_json)

# Extraer los datos necesarios
IoU_list= datos_json['IoU_list']
class_names = datos_json['class_names']

# Ahora puedes usar IoU_list_recuperado y class_names_recuperado según sea necesario

"""**HISTOGRAMA DEL ARCHIVO EXTRAIDO**"""

clss=4
# Obtener la lista de IoU para la clase específica
IoU_clase = IoU_list[class_names[clss]]
# Obtener la lista de IoU para la clase específica
IoU_clase = IoU_list[class_names[clss]]

# Filtrar los valores por encima de 0.1
IoU_filtrado = [x for x in IoU_clase if x > 0]

# Imprimir estadísticas
print('Number of Evaluations for Class {}: {}'.format(class_names[clss], len(IoU_filtrado)))
print('Average IoU for Class {}: {:.4f}'.format(class_names[clss], np.mean(IoU_filtrado)))
print('Standard Deviation for Class {}: {:.4f}'.format(class_names[clss], np.std(IoU_filtrado)))

# Graficar el histograma y el boxplot actualizado
plt.hist(IoU_filtrado)
plt.title('IoU Histogram for Class {} (Filtered)'.format(class_names[clss]))
plt.show()
plt.boxplot(IoU_filtrado)
plt.title('IoU Boxplot for Class {} (Filtered)'.format(class_names[clss]))
plt.show()

"""# **MIRAR ETIQUETAS IOU**"""

import matplotlib.pyplot as plt
import numpy as np
IOU_class_comparador(dataset_train, model, plot_results=True)